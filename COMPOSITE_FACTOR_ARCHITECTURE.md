# RD-Agent å¤åˆå› å­æ¶æ„è®¾è®¡æ–¹æ¡ˆ

## ğŸ“Š é—®é¢˜åˆ†æ

### å½“å‰çŠ¶æ€
1. **æ•°æ®æºå•ä¸€**ï¼šåªä½¿ç”¨æ—¥é¢‘ä»·æ ¼/æˆäº¤é‡æ•°æ®ï¼ˆOHLCVï¼‰
2. **å› å­ç±»å‹å±€é™**ï¼šæ‰€æœ‰ç”Ÿæˆçš„å› å­éƒ½æ˜¯æŠ€æœ¯åˆ†æå› å­
3. **æ”¶ç›Šç‡ç“¶é¢ˆ**ï¼šç¬¬27è½®è¿è¡Œä¸­IC/Rank ICè¡¨ç°å¹³å¹³

### å¯ç”¨æ•°æ®æº
æ ¹æ®Qlibå’ŒTushareçš„ç ”ç©¶ï¼Œä»¥ä¸‹æ•°æ®å·²å¯ç”¨ï¼š

#### 1ï¸âƒ£ è´¢åŠ¡æ•°æ®ï¼ˆTushare Proï¼‰
```python
# ä¼°å€¼æŒ‡æ ‡
PE, PE_TTM      # å¸‚ç›ˆç‡
PB, PS, PS_TTM  # å¸‚å‡€ç‡ã€å¸‚é”€ç‡

# ç›ˆåˆ©èƒ½åŠ›
ROE, ROA        # å‡€èµ„äº§æ”¶ç›Šç‡ã€æ€»èµ„äº§æ”¶ç›Šç‡
OperatingProfitGrowRate  # è¥ä¸šåˆ©æ¶¦å¢é•¿ç‡
NetProfitGrowRate        # å‡€åˆ©æ¶¦å¢é•¿ç‡

# æˆé•¿èƒ½åŠ›
OperatingRevenueGrowRate # è¥ä¸šæ”¶å…¥å¢é•¿ç‡

# å¿å€ºèƒ½åŠ›
DebtToAssets    # èµ„äº§è´Ÿå€ºç‡
CurrentRatio    # æµåŠ¨æ¯”ç‡

# è¿è¥èƒ½åŠ›
TotalAssetTurnover      # æ€»èµ„äº§å‘¨è½¬ç‡
InventoryTurnover       # å­˜è´§å‘¨è½¬ç‡

# å¸‚å€¼æ•°æ®
TotalMV, CircMV         # æ€»å¸‚å€¼ã€æµé€šå¸‚å€¼
```

#### 2ï¸âƒ£ è¡Œä¸šæ•°æ®ï¼ˆç”³ä¸‡2021åˆ†ç±»ï¼‰
```python
# L1ï¼ˆä¸€çº§è¡Œä¸šï¼‰ï¼š29ä¸ª
# æœºæ¢°è®¾å¤‡, ç”µå­, åŒ»è¯ç”Ÿç‰©, åŒ–å·¥, æ±½è½¦, è®¡ç®—æœº, etc.

# L2ï¼ˆäºŒçº§è¡Œä¸šï¼‰ï¼š110ä¸ª
# ç”µæ°”è®¾å¤‡, å…ƒå™¨ä»¶, è½¯ä»¶æœåŠ¡, ä¸“ç”¨æœºæ¢°, æ±½è½¦é…ä»¶, etc.

# æ•°æ®æ¥æºï¼š~/.qlib/qlib_data/cn_data/industry_data/
# æ–‡ä»¶ï¼štushare_stock_to_industry_dict_*.json
```

---

## ğŸ¯ å¤åˆå› å­æ¶æ„è®¾è®¡

### æ ¸å¿ƒç†å¿µï¼šä¸‰å±‚å› å­èåˆ
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Layer 3: Ensemble Factor               â”‚
â”‚      (Final Combined Alpha Signal)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       Layer 2: Cross-Sectional Normalization    â”‚
â”‚    (Time-specific Z-score, Industry Neutral)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†•
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Technical â”‚  Financial â”‚  Industry  â”‚ Interaction  â”‚
â”‚  Factors  â”‚  Factors  â”‚  Factors  â”‚   Factors   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ—ï¸ å®ç°æ–¹æ¡ˆ

### Phase 1: æ•°æ®å±‚æ”¹é€ 

#### 1.1 æ‰©å±•æ•°æ®ç”Ÿæˆè„šæœ¬
ä¿®æ”¹ `rdagent/scenarios/qlib/experiment/factor_data_template/generate.py`ï¼š

```python
import qlib
from qlib.data import D

# æ–°å¢ï¼šåŠ è½½è´¢åŠ¡æ•°æ®
financial_fields = [
    # åŸºç¡€è¡Œæƒ…
    "$open", "$close", "$high", "$low", "$volume", "$amount",
    # ä¼°å€¼æŒ‡æ ‡
    "PE", "PE_TTM", "PB", "PS", "PS_TTM",
    # ç›ˆåˆ©èƒ½åŠ›
    "ROE", "ROA", "OperatingProfitGrowRate", "NetProfitGrowRate",
    # æˆé•¿èƒ½åŠ›
    "OperatingRevenueGrowRate",
    # å¸‚å€¼
    "TotalMV", "CircMV",
]

data_financial = D.features(
    instruments,
    financial_fields,
    freq="day"
).swaplevel().sort_index().loc["2008-12-29":].sort_index()

data_financial.to_hdf("./daily_pv_financial_all.h5", key="data")

# æ–°å¢ï¼šç”Ÿæˆè¡Œä¸šåˆ†ç±»æ•°æ®
import json
from pathlib import Path

industry_file = Path.home() / '.qlib/qlib_data/cn_data/industry_data/tushare_stock_to_industry_dict_20251229_161019.json'
with open(industry_file) as f:
    industry_mapping = json.load(f)

# è½¬æ¢ä¸ºDataFrameå¹¶ä¿å­˜
industry_df = pd.DataFrame([
    {"instrument": k, "industry_l1": v.get("industry_l1"), "industry_l2": v.get("industry_l2")}
    for k, v in industry_mapping.items()
])
industry_df.to_hdf("./industry_classification.h5", key="data")
```

#### 1.2 åˆ›å»ºæ•°æ®åŠ è½½å·¥å…·ç±»
æ–°å»º `rdagent/scenarios/qlib/experiment/utils_enhanced.py`ï¼š

```python
import pandas as pd
import numpy as np
from pathlib import Path
from typing import Optional, List, Dict

class EnhancedDataLoader:
    """å¢å¼ºçš„æ•°æ®åŠ è½½å™¨ï¼Œæ”¯æŒå¤šæºæ•°æ®"""

    def __init__(self, data_folder: str):
        self.data_folder = Path(data_folder)

    def load_base_data(self) -> pd.DataFrame:
        """åŠ è½½åŸºç¡€ä»·æ ¼/æˆäº¤é‡æ•°æ®"""
        return pd.read_hdf(self.data_folder / "daily_pv.h5", key='data')

    def load_financial_data(self) -> pd.DataFrame:
        """åŠ è½½è´¢åŠ¡æ•°æ®"""
        path = self.data_folder / "daily_pv_financial.h5"
        if path.exists():
            return pd.read_hdf(path, key='data')
        return pd.DataFrame()

    def load_industry_mapping(self) -> Dict[str, Dict[str, str]]:
        """åŠ è½½è¡Œä¸šåˆ†ç±»æ˜ å°„"""
        path = self.data_folder / "industry_classification.h5"
        if path.exists():
            df = pd.read_hdf(path, key='data')
            return df.set_index('instrument').to_dict('index')
        return {}

    def merge_all_data(self,
                       base_df: pd.DataFrame,
                       financial_df: Optional[pd.DataFrame] = None,
                       industry_mapping: Optional[Dict] = None) -> pd.DataFrame:
        """åˆå¹¶æ‰€æœ‰æ•°æ®æº"""

        df = base_df.copy()

        # åˆå¹¶è´¢åŠ¡æ•°æ®
        if financial_df is not None and len(financial_df) > 0:
            df = df.join(financial_df, how='left')

        # æ·»åŠ è¡Œä¸šåˆ†ç±»
        if industry_mapping:
            df_reset = df.reset_index()
            df_reset['industry_l1'] = df_reset['instrument'].map(
                lambda x: industry_mapping.get(x, {}).get('industry_l1', 'Unknown')
            )
            df_reset['industry_l2'] = df_reset['instrument'].map(
                lambda x: industry_mapping.get(x, {}).get('industry_l2', 'Unknown')
            )
            df = df_reset.set_index(['datetime', 'instrument'])

        return df
```

---

### Phase 2: å› å­å±‚å¢å¼º

#### 2.1 åˆ›å»ºå¤åˆå› å­æ¨¡æ¿åº“
æ–°å»º `rdagent/components/coder/factor_coder/composite_templates.py`ï¼š

```python
"""
å¤åˆå› å­æ¨¡æ¿åº“

æä¾›è´¢åŠ¡å› å­ã€è¡Œä¸šå› å­å’Œäº¤äº’å› å­çš„æ ‡å‡†æ¨¡æ¿
"""

# ==================== è´¢åŠ¡å› å­æ¨¡æ¿ ====================

FINANCIAL_FACTOR_PE = """
def calculate_PE_Momentum():
    import pandas as pd
    import numpy as np

    df = pd.read_hdf('daily_pv_financial.h5', key='data')
    df_reset = df.reset_index()

    # PEåŠ¨é‡å› å­ï¼šä½PEè‚¡ç¥¨çš„åŠ¨é‡æ•ˆåº”
    # é€»è¾‘ï¼šä½ä¼°å€¼è‚¡ç¥¨å¯èƒ½æœ‰æ›´å¥½çš„ä¸Šæ¶¨ç©ºé—´

    # è®¡ç®—PEçš„æ¨ªæˆªé¢åˆ†ä½æ•°ï¼ˆæ¯å¤©ï¼‰
    df_reset['PE_percentile'] = df_reset.groupby('datetime')['PE'].transform(
        lambda x: x.rank(pct=True)
    )

    # ä½PEå®šä¹‰ä¸ºåˆ†ä½æ•°<0.3
    df_reset['Low_PE'] = (df_reset['PE_percentile'] < 0.3).astype(int)

    # è®¡ç®—åŠ¨é‡ï¼ˆ20æ—¥æ”¶ç›Šç‡ï¼‰
    df_reset['momentum_20d'] = df_reset.groupby('instrument')['$close'].transform(
        lambda x: x.pct_change(periods=20)
    )

    # PEåŠ¨é‡å› å­ = åŠ¨é‡ Ã— (1 - PEåˆ†ä½æ•°)
    # ä½PEè‚¡ç¥¨è·å¾—æ›´é«˜æƒé‡
    df_reset['PE_Momentum'] = df_reset['momentum_20d'] * (1 - df_reset['PE_percentile'])

    result = df_reset.set_index(['datetime', 'instrument'])[['PE_Momentum']]
    result.to_hdf('result.h5', key='data')
"""

FINANCIAL_FACTOR_ROE = """
def calculate_ROE_Trend():
    import pandas as pd
    import numpy as np

    df = pd.read_hdf('daily_pv_financial.h5', key='data')
    df_reset = df.reset_index()

    # ROEè¶‹åŠ¿å› å­ï¼šå¯»æ‰¾ç›ˆåˆ©èƒ½åŠ›æŒç»­æ”¹å–„çš„å…¬å¸

    # è®¡ç®—ROEçš„60æ—¥å˜åŒ–ç‡
    df_reset = df_reset.sort_values(['instrument', 'datetime'])
    df_reset['ROE_change'] = df_reset.groupby('instrument')['ROE'].transform(
        lambda x: x.pct_change(periods=60)
    )

    # æ ‡å‡†åŒ–ROEå’ŒROEå˜åŒ–
    df_reset['ROE_zscore'] = df_reset.groupby('datetime')['ROE'].transform(
        lambda x: (x - x.mean()) / (x.std() + 1e-12)
    )
    df_reset['ROE_change_zscore'] = df_reset.groupby('datetime')['ROE_change'].transform(
        lambda x: (x - x.mean()) / (x.std() + 1e-12)
    )

    # ROEè¶‹åŠ¿å› å­ = é«˜ROE + ä¸Šå‡è¶‹åŠ¿
    df_reset['ROE_Trend'] = (
        df_reset['ROE_zscore'] * 0.5 +
        df_reset['ROE_change_zscore'] * 0.5
    )

    result = df_reset.set_index(['datetime', 'instrument'])[['ROE_Trend']]
    result.to_hdf('result.h5', key='data')
"""

# ==================== è¡Œä¸šå› å­æ¨¡æ¿ ====================

INDUSTRY_FACTOR_MOMENTUM = """
def calculate_Industry_Momentum():
    import pandas as pd
    import numpy as np
    import json
    from pathlib import Path

    df = pd.read_hdf('daily_pv.h5', key='data')
    df_reset = df.reset_index()

    # åŠ è½½è¡Œä¸šåˆ†ç±»
    industry_file = Path.home() / '.qlib/qlib_data/cn_data/industry_data/tushare_stock_to_industry_dict_20251229_161019.json'
    with open(industry_file) as f:
        industry_mapping = json.load(f)

    # æ˜ å°„è‚¡ç¥¨åˆ°L2è¡Œä¸šï¼ˆ110ä¸ªç»†åˆ†è¡Œä¸šï¼‰
    df_reset['industry_l2'] = df_reset['instrument'].map(
        lambda x: industry_mapping.get(x, {}).get('industry_l2', 'Unknown')
    )

    # è®¡ç®—ä¸ªè‚¡åŠ¨é‡ï¼ˆ5æ—¥æ”¶ç›Šç‡ï¼‰
    df_reset['stock_return_5d'] = df_reset.groupby('instrument')['$close'].transform(
        lambda x: x.pct_change(periods=5)
    )

    # è®¡ç®—è¡Œä¸šå¹³å‡åŠ¨é‡
    industry_momentum = df_reset.groupby(['datetime', 'industry_l2'])['stock_return_5d'].transform('mean')

    # è¡Œä¸šåŠ¨é‡å› å­ï¼šä½¿ç”¨è¡Œä¸šåŠ¨é‡ä½œä¸ºå› å­å€¼
    df_reset['Industry_Momentum'] = industry_momentum.values

    # è¿‡æ»¤æ‰æ— è¡Œä¸šåˆ†ç±»çš„è‚¡ç¥¨
    df_valid = df_reset[df_reset['industry_l2'] != 'Unknown'].copy()

    result = df_valid.set_index(['datetime', 'instrument'])[['Industry_Momentum']]
    result.to_hdf('result.h5', key='data')
"""

INDUSTRY_FACTOR_RELATIVE_STRENGTH = """
def calculate_Industry_Relative_Strength():
    import pandas as pd
    import numpy as np
    import json
    from pathlib import Path

    df = pd.read_hdf('daily_pv.h5', key='data')
    df_reset = df.reset_index()

    # åŠ è½½è¡Œä¸šåˆ†ç±»
    industry_file = Path.home() / '.qlib/qlib_data/cn_data/industry_data/tushare_stock_to_industry_dict_20251229_161019.json'
    with open(industry_file) as f:
        industry_mapping = json.load(f)

    df_reset['industry_l2'] = df_reset['instrument'].map(
        lambda x: industry_mapping.get(x, {}).get('industry_l2', 'Unknown')
    )

    # è®¡ç®—ä¸ªè‚¡æ”¶ç›Šç‡
    df_reset['stock_return'] = df_reset.groupby('instrument')['$close'].transform(
        lambda x: x.pct_change(periods=10)
    )

    # è®¡ç®—è¡Œä¸šå¹³å‡æ”¶ç›Šç‡
    industry_return = df_reset.groupby(['datetime', 'industry_l2'])['stock_return'].transform('mean')

    # è¡Œä¸šç›¸å¯¹å¼ºåº¦ = ä¸ªè‚¡æ”¶ç›Š - è¡Œä¸šæ”¶ç›Š
    df_reset['Industry_Relative_Strength'] = df_reset['stock_return'] - industry_return

    # è¿‡æ»¤
    df_valid = df_reset[df_reset['industry_l2'] != 'Unknown'].copy()

    result = df_valid.set_index(['datetime', 'instrument'])[['Industry_Relative_Strength']]
    result.to_hdf('result.h5', key='data')
"""

# ==================== äº¤äº’å› å­æ¨¡æ¿ ====================

INTERACTION_FACTOR_VALUE_MOMENTUM = """
def calculate_Value_Momentum_Combo():
    import pandas as pd
    import numpy as np
    import json
    from pathlib import Path

    df = pd.read_hdf('daily_pv_financial.h5', key='data')
    df_reset = df.reset_index()

    # åŠ è½½è¡Œä¸šåˆ†ç±»
    industry_file = Path.home() / '.qlib/qlib_data/cn_data/industry_data/tushare_stock_to_industry_dict_20251229_161019.json'
    with open(industry_file) as f:
        industry_mapping = json.load(f)

    df_reset['industry_l2'] = df_reset['instrument'].map(
        lambda x: industry_mapping.get(x, {}).get('industry_l2', 'Unknown')
    )

    # 1. è®¡ç®—ä»·å€¼ä¿¡å·ï¼ˆPEåˆ†ä½æ•°å€’æ•°ï¼‰
    df_reset['PE_signal'] = df_reset.groupby('datetime')['PE'].transform(
        lambda x: 1 - (x.rank(pct=True))
    )

    # 2. è®¡ç®—åŠ¨é‡ä¿¡å·
    df_reset['momentum_signal'] = df_reset.groupby('instrument')['$close'].transform(
        lambda x: x.pct_change(periods=20)
    )
    df_reset['momentum_signal'] = df_reset.groupby('datetime')['momentum_signal'].transform(
        lambda x: (x - x.mean()) / (x.std() + 1e-12)
    )

    # 3. è®¡ç®—è¡Œä¸šåŠ¨é‡
    df_reset['stock_return'] = df_reset.groupby('instrument')['$close'].transform(
        lambda x: x.pct_change(periods=5)
    )
    df_reset['industry_momentum'] = df_reset.groupby(['datetime', 'industry_l2'])['stock_return'].transform('mean')

    # 4. ç»„åˆå› å­ = ä»·å€¼ä¿¡å· + åŠ¨é‡ä¿¡å· + è¡Œä¸šåŠ¨é‡
    df_reset['Value_Momentum_Combo'] = (
        df_reset['PE_signal'] * 0.3 +
        df_reset['momentum_signal'] * 0.5 +
        df_reset['industry_momentum'] * 0.2
    )

    # è¿‡æ»¤
    df_valid = df_reset[(df_reset['industry_l2'] != 'Unknown') & (df_reset['PE'].notna())].copy()

    result = df_valid.set_index(['datetime', 'instrument'])[['Value_Momentum_Combo']]
    result.to_hdf('result.h5', key='data')
"""

INTERACTION_FACTOR_QUALITY_MOMENTUM = """
def calculate_Quality_Momentum_Combo():
    import pandas as pd
    import numpy as np

    df = pd.read_hdf('daily_pv_financial.h5', key='data')
    df_reset = df.reset_index()

    # 1. è´¨é‡ä¿¡å·ï¼ˆROE + ROAï¼‰
    df_reset['quality_signal'] = (
        df_reset.groupby('datetime')['ROE'].transform(
            lambda x: (x - x.mean()) / (x.std() + 1e-12)
        ) +
        df_reset.groupby('datetime')['ROA'].transform(
            lambda x: (x - x.mean()) / (x.std() + 1e-12)
        )
    ) / 2

    # 2. æˆé•¿ä¿¡å·ï¼ˆè¥æ”¶å¢é•¿ + åˆ©æ¶¦å¢é•¿ï¼‰
    df_reset['growth_signal'] = (
        df_reset.groupby('datetime')['OperatingRevenueGrowRate'].transform(
            lambda x: (x - x.mean()) / (x.std() + 1e-12)
        ) +
        df_reset.groupby('datetime')['NetProfitGrowRate'].transform(
            lambda x: (x - x.mean()) / (x.std() + 1e-12)
        )
    ) / 2

    # 3. åŠ¨é‡ä¿¡å·
    df_reset['momentum_signal'] = df_reset.groupby('instrument')['$close'].transform(
        lambda x: x.pct_change(periods=20)
    )
    df_reset['momentum_signal'] = df_reset.groupby('datetime')['momentum_signal'].transform(
        lambda x: (x - x.mean()) / (x.std() + 1e-12)
    )

    # 4. ç»„åˆï¼šè´¨é‡(0.3) + æˆé•¿(0.3) + åŠ¨é‡(0.4)
    df_reset['Quality_Momentum_Combo'] = (
        df_reset['quality_signal'] * 0.3 +
        df_reset['growth_signal'] * 0.3 +
        df_reset['momentum_signal'] * 0.4
    )

    result = df_reset.set_index(['datetime', 'instrument'])[['Quality_Momentum_Combo']]
    result.to_hdf('result.h5', key='data')
"""
```

---

### Phase 3: æç¤ºè¯å¢å¼º

#### 3.1 ä¿®æ”¹ `prompts.yaml`
åœ¨ç°æœ‰çš„æç¤ºè¯ä¸­æ·»åŠ ï¼š

```yaml
# ========== æ–°å¢ï¼šå¤šæºæ•°æ®å› å­æ¨¡æ¿ ==========

COMPOSITE_FACTOR_INTRODUCTION: |-
  IMPORTANT - Multi-Source Data Strategy:

  Your factors should COMBINE multiple data sources for better performance:

  1. Technical Factors (price/volume): Short-term signals
  2. Financial Factors (fundamentals): Long-term value
  3. Industry Factors (sector trends): Context-aware signals
  4. Interaction Factors: Synergy between different domains

  EXAMPLE COMBINATIONS:
  - Value + Momentum: Low PE stocks with strong momentum
  - Quality + Growth: High ROE + High revenue growth
  - Industry Rotation: Sector momentum + individual stock strength
  - Multi-factor: Combine 3+ different signal sources

COMPOSITE_FACTOR_EXAMPLE_TEMPLATES: |-
  {% include 'composite_templates.py' %}

FACTOR_SELECTION_GUIDANCE: |-
  When selecting factors, prioritize:
  1. Financial + Technical combinations (highest alpha)
  2. Industry-neutral factors (more robust)
  3. Cross-sectional normalization (critical)
  4. Interaction effects (non-linear value)
```

---

### Phase 4: è¯„ä¼°å™¨å¢å¼º

#### 4.1 æ·»åŠ å¤åˆå› å­è¯„ä¼°æŒ‡æ ‡
æ–°å»º `rdagent/components/coder/factor_coder/composite_evaluator.py`ï¼š

```python
"""
å¤åˆå› å­è¯„ä¼°å™¨

è¯„ä¼°å¤åˆå› å­çš„å¤šç»´åº¦è¡¨ç°
"""

class CompositeFactorEvaluator:
    """å¤åˆå› å­è¯„ä¼°å™¨"""

    @staticmethod
    def evaluate_interaction_effects(factor_df: pd.DataFrame) -> Dict:
        """è¯„ä¼°å› å­é—´çš„äº¤äº’æ•ˆåº”"""

        # 1. å•å› å­IC
        single_ics = {}

        # 2. ç»„åˆå› å­IC
        combined_ic = ...

        # 3. äº¤äº’æ•ˆåº”å¢é‡
        interaction_gain = combined_ic - max(single_ics.values())

        return {
            "single_ics": single_ics,
            "combined_ic": combined_ic,
            "interaction_gain": interaction_gain,
            "synergy_score": interaction_gain / max(single_ics.values())
        }

    @staticmethod
    def evaluate_industry_neutrality(factor_df: pd.DataFrame,
                                     industry_mapping: Dict) -> Dict:
        """è¯„ä¼°è¡Œä¸šä¸­æ€§åŒ–ç¨‹åº¦"""

        # è®¡ç®—è¡Œä¸šæš´éœ²åº¦
        industry_exposure = ...

        # è®¡ç®—ä¸»åŠ¨é£é™©
        active_risk = ...

        return {
            "industry_neutral": industry_exposure < 0.1,
            "active_risk": active_risk,
            "concentration_ratio": ...
        }

    @staticmethod
    def evaluate_turnover(factor_series: pd.Series) -> Dict:
        """è¯„ä¼°å› å­æ¢æ‰‹ç‡"""

        turnover = factor_series.diff().abs().mean()

        return {
            "avg_turnover": turnover,
            "turnover_stability": ...
        }
```

---

## ğŸ“ˆ é¢„æœŸæ•ˆæœ

### æ”¶ç›Šç‡æå‡è·¯å¾„

1. **å•å› å­ä¼˜åŒ–**ï¼ˆICæå‡0.02-0.05ï¼‰
   - è´¢åŠ¡å› å­ï¼šä»·å€¼ã€è´¨é‡ã€æˆé•¿
   - è¡Œä¸šå› å­ï¼šè¡Œä¸šåŠ¨é‡ã€ç›¸å¯¹å¼ºåº¦

2. **ç»„åˆå› å­**ï¼ˆICå†æå‡0.03-0.08ï¼‰
   - ä»·å€¼+åŠ¨é‡ï¼šç»å…¸ç»„åˆ
   - è´¨é‡+æˆé•¿ï¼šåŸºæœ¬é¢é©±åŠ¨
   - è¡Œä¸šä¸­æ€§ï¼šé™ä½é£é™©

3. **åŠ¨æ€æƒé‡**ï¼ˆICå†æå‡0.02-0.04ï¼‰
   - å¸‚åœºçŠ¶æ€è¯†åˆ«
   - å› å­æƒé‡è‡ªé€‚åº”

**é¢„æœŸæ€»ICæå‡ï¼š0.07 - 0.17**

---

## ğŸš€ å®æ–½æ­¥éª¤

### Step 1: æ•°æ®å‡†å¤‡ âœ… **å·²å®Œæˆ**
- [x] è´¢åŠ¡æ•°æ®è½¬æ¢è„šæœ¬ `scripts/convert_tushare_financial_to_hdf5.py`
- [x] æ•°æ®åˆå¹¶è„šæœ¬ `scripts/merge_financial_price_data.py`
- [x] å‰å‘å¡«å……è„šæœ¬ `scripts/forward_fill_financial_data.py`
- [x] æ•°æ®éªŒè¯ï¼š7,584,444è¡Œ Ã— 29åˆ—ï¼Œ3875åªè‚¡ç¥¨
- [x] è´¢åŠ¡å­—æ®µè¦†ç›–ç‡ï¼š5.74%ï¼ˆå‰å‘å¡«å……åï¼‰

### Step 2: å·¥å…·ç±»å¼€å‘ âœ… **å·²å®Œæˆ**
- [x] å®ç° `EnhancedDataLoader` (`rdagent/scenarios/qlib/experiment/utils_enhanced.py`)
- [x] å®ç°å¤åˆå› å­æ¨¡æ¿åº“ (`rdagent/components/coder/factor_coder/composite_templates.py`)
- [x] å•å…ƒæµ‹è¯• (`scripts/test_composite_factor.py`)
- [x] æµ‹è¯•ç»“æœï¼šROEè¶‹åŠ¿å› å­ã€è´¨é‡+åŠ¨é‡ç»„åˆå› å­å‡é€šè¿‡

### Step 3: æç¤ºè¯ä¼˜åŒ– âœ… **å·²å®Œæˆ**
- [x] æ›´æ–° `prompts.yaml` æ·»åŠ  `composite_factor_priority_guidance`
- [x] æ·»åŠ 4ä¸ªå¤åˆå› å­ç¤ºä¾‹æ¨¡æ¿
- [x] æ·»åŠ å› å­é€‰æ‹©å¼•å¯¼å’Œå¤šæºæ•°æ®ç­–ç•¥è¯´æ˜

### Step 4: è¯„ä¼°å™¨å¢å¼º â³ **å¾…å®æ–½**
- [ ] å®ç°å¤åˆå› å­è¯„ä¼°å™¨
- [ ] æ·»åŠ äº¤äº’æ•ˆåº”è¯„ä¼°
- [ ] æ·»åŠ è¡Œä¸šä¸­æ€§è¯„ä¼°

### Step 5: é›†æˆæµ‹è¯• â³ **è¿›è¡Œä¸­**
- [x] ç«¯åˆ°ç«¯æµ‹è¯•ï¼ˆå¤åˆå› å­ç”Ÿæˆï¼‰
- [ ] æ€§èƒ½å¯¹æ¯”ï¼ˆæ–°æ—§å› å­ICå¯¹æ¯”ï¼‰
- [ ] å‚æ•°è°ƒä¼˜

**å®Œæˆè¿›åº¦ï¼š3/5 (60%)**

---

## ğŸ”‘ å…³é”®æˆåŠŸå› ç´ 

1. **æ•°æ®è´¨é‡**ï¼šç¡®ä¿è´¢åŠ¡æ•°æ®å’Œè¡Œä¸šåˆ†ç±»å‡†ç¡®
2. **å‰ç»æ€§**ï¼šé¿å…ä½¿ç”¨æœªæ¥æ•°æ®ï¼ˆæ—¶é—´æ³„æ¼ï¼‰
3. **æ ‡å‡†åŒ–**ï¼šæ‰€æœ‰å› å­å¿…é¡»æ¨ªæˆªé¢æ ‡å‡†åŒ–
4. **è¡Œä¸šä¸­æ€§**ï¼šé™ä½è¡Œä¸šåç¦»åº¦
5. **æ¢æ‰‹ç‡æ§åˆ¶**ï¼šå¹³è¡¡å› å­æ•ˆæœå’Œäº¤æ˜“æˆæœ¬

---

## ğŸ“š å‚è€ƒèµ„æ–™

1. **å› å­æŠ•èµ„ç»å…¸æ–‡çŒ®**
   - Fama-French äº”å› å­æ¨¡å‹
   - Grinold-Kahn ç§¯æç®¡ç†
   - Qlibé‡åŒ–æ¡†æ¶æ–‡æ¡£

2. **è¡Œä¸šåˆ†ç±»æ ‡å‡†**
   - ç”³ä¸‡2021è¡Œä¸šåˆ†ç±»
   - Tushareè¡Œä¸šæ•°æ®API

3. **è´¢åŠ¡åˆ†æ**
   - æœé‚¦åˆ†ææ³•
   - è´¢åŠ¡æ¯”ç‡æ‰‹å†Œ

---

## âœ… å·²å®Œæˆå·¥ä½œæ€»ç»“

### æ•°æ®å¤„ç†æµç¨‹ï¼ˆ2025-12-30å®Œæˆï¼‰

#### 1. è´¢åŠ¡æ•°æ®è½¬æ¢
**æ–‡ä»¶**: `scripts/convert_tushare_financial_to_hdf5.py`

**åŠŸèƒ½**:
- è¯»å–Tushareè´¢åŠ¡CSVæ•°æ®ï¼ˆ184,436è¡Œï¼‰
- è½¬æ¢è‚¡ç¥¨ä»£ç æ ¼å¼ï¼ˆ000001.SZ â†’ 000001SZï¼‰
- æ˜ å°„21ä¸ªè´¢åŠ¡æŒ‡æ ‡å­—æ®µ
- ç”ŸæˆHDF5æ ¼å¼è¾“å‡ºï¼ˆ32.95 MBï¼‰

**è´¢åŠ¡å­—æ®µæ˜ å°„**:
```python
FINANCIAL_FIELDS_MAPPING = {
    # ä¼°å€¼æŒ‡æ ‡
    "eps": "EPS", "bps": "BPS", "ocfps": "OCFPS", "cfps": "CFPS",
    # ç›ˆåˆ©èƒ½åŠ›
    "roe": "ROE", "roa": "ROA", "roic": "ROIC",
    "netprofit_margin": "NetProfitMargin", "grossprofit_margin": "GrossProfitMargin",
    # æˆé•¿èƒ½åŠ›
    "basic_eps_yoy": "EPS_Growth", "cfps_yoy": "CFPS_Growth",
    "netprofit_yoy": "NetProfit_Growth", "op_yoy": "OP_Growth",
    # å¿å€ºèƒ½åŠ›
    "debt_to_assets": "DebtToAssets", "current_ratio": "CurrentRatio",
    "quick_ratio": "QuickRatio", "ocf_to_debt": "OCF_To_Debt",
    # è¿è¥èƒ½åŠ›
    "assets_turn": "AssetsTurnover", "ar_turn": "AR_Turnover", "ca_turn": "CA_Turnover",
    # å…¶ä»–
    "ebitda": "EBITDA",
}
```

#### 2. æ•°æ®åˆå¹¶
**æ–‡ä»¶**: `scripts/merge_financial_price_data.py`

**åŠŸèƒ½**:
- è§£å†³è‚¡ç¥¨ä»£ç æ ¼å¼ä¸åŒ¹é…é—®é¢˜
  - ä»·æ ¼æ•°æ®ï¼šSH600000, SZ000001
  - è´¢åŠ¡æ•°æ®ï¼š000001.SZ
- æ ‡å‡†åŒ–ä»£ç æ ¼å¼ååˆå¹¶
- ç”Ÿæˆåˆå¹¶æ•°æ®ï¼ˆ1.5 GB, 7,584,444è¡Œ Ã— 29åˆ—ï¼‰

**åŒ¹é…ç»“æœ**:
- ä»·æ ¼æ•°æ®è‚¡ç¥¨æ•°ï¼š3,875
- è´¢åŠ¡æ•°æ®è‚¡ç¥¨æ•°ï¼š5,466
- åŒ¹é…è‚¡ç¥¨æ•°ï¼š3,661

#### 3. å‰å‘å¡«å……å¤„ç†
**æ–‡ä»¶**: `scripts/forward_fill_financial_data.py`

**åŠŸèƒ½**:
- å¯¹æ¯åªè‚¡ç¥¨ç‹¬ç«‹è¿›è¡Œå‰å‘å¡«å……
- æœ€å¤§å¡«å……å‘¨æœŸï¼š500ä¸ªäº¤æ˜“æ—¥ï¼ˆçº¦1.5å¹´ï¼‰
- å°†è´¢åŠ¡æ•°æ®è¦†ç›–ç‡ä»0.09%æå‡åˆ°5.74%
- é¢å¤–å¡«å……428,000+è¡Œæ•°æ®

**å¡«å……å‰åå¯¹æ¯”**:
| å­—æ®µ | å¡«å……å‰è¦†ç›–ç‡ | å¡«å……åè¦†ç›–ç‡ | å¢åŠ è¡Œæ•° |
|------|-------------|-------------|----------|
| EPS | 0.09% | 5.74% | +427,972 |
| ROE | 0.09% | 5.71% | +425,978 |
| ROA | 0.09% | 5.60% | +422,894 |

### ä»£ç å®ç°

#### 1. å¢å¼ºæ•°æ®åŠ è½½å™¨
**æ–‡ä»¶**: `rdagent/scenarios/qlib/experiment/utils_enhanced.py`

**æ ¸å¿ƒç±»**: `EnhancedDataLoader`

**æ–¹æ³•**:
```python
class EnhancedDataLoader:
    def load_base_data(self) -> pd.DataFrame
    def load_financial_data(self) -> pd.DataFrame
    def load_industry_mapping(self) -> Dict[str, Dict[str, str]]
    def merge_all_data(self, base_df, financial_df, industry_mapping) -> pd.DataFrame
    def get_industry_groups(self, df, level="l2") -> Dict[str, List[str]]
    def get_available_fields(self, df) -> Dict[str, List[str]]
```

#### 2. å¤åˆå› å­æ¨¡æ¿åº“
**æ–‡ä»¶**: `rdagent/components/coder/factor_coder/composite_templates.py`

**æ¨¡æ¿åˆ†ç±»**:
- **è´¢åŠ¡å› å­**: PE_Momentum, ROE_Trend
- **è¡Œä¸šå› å­**: Industry_Momentum, Industry_Relative_Strength
- **äº¤äº’å› å­**: Value_Momentum_Combo, Quality_Growth_Momentum_Combo

#### 3. æç¤ºè¯å¢å¼º
**æ–‡ä»¶**: `rdagent/components/coder/factor_coder/prompts.yaml`

**æ–°å¢å†…å®¹**:
- `composite_factor_priority_guidance`: å¤šæºæ•°æ®ç­–ç•¥æŒ‡å¯¼
- 4ä¸ªå®Œæ•´çš„å¤åˆå› å­ç¤ºä¾‹æ¨¡æ¿
- ç ”ç©¶æ”¯æŒçš„å› å­ç»„åˆå»ºè®®

### æµ‹è¯•éªŒè¯

#### æµ‹è¯•è„šæœ¬
**æ–‡ä»¶**: `scripts/test_composite_factor.py`

**æµ‹è¯•ç»“æœ**:

**æµ‹è¯•1: ROEè¶‹åŠ¿å› å­**
- å› å­è¦†ç›–ç‡ï¼š2.91%
- å› å­å‡å€¼ï¼š-0.0016ï¼ˆæ ‡å‡†åŒ–æ­£ç¡®ï¼‰
- å› å­æ ‡å‡†å·®ï¼š0.6937
- æ ·æœ¬å€¼ï¼šSZ300841çš„ROE_Trend=0.3845

**æµ‹è¯•2: è´¨é‡+åŠ¨é‡ç»„åˆå› å­**
- å› å­è¦†ç›–ç‡ï¼š5.57%
- å› å­å‡å€¼ï¼š0.0075
- å› å­æ ‡å‡†å·®ï¼š0.6506
- æ ·æœ¬å€¼ï¼š
  - SZ300841: Quality=1.98, Combo=0.64
  - SZ300837: Quality=0.79, Combo=0.37

### æ•°æ®æ–‡ä»¶ä½ç½®

```
~/.qlib/qlib_data/cn_data/financial_data/
â”œâ”€â”€ a_share_financial_latest.csv          # åŸå§‹Tushareæ•°æ®
â”œâ”€â”€ daily_pv_financial.h5                 # è½¬æ¢åHDF5ï¼ˆ32.95 MBï¼‰
â”œâ”€â”€ daily_pv_financial_merged.h5          # åˆå¹¶åæ•°æ®ï¼ˆ1.5 GBï¼‰
â””â”€â”€ daily_pv_financial_filled.h5          # å‰å‘å¡«å……åï¼ˆ1.5 GBï¼‰

git_ignore_folder/factor_implementation_source_data/
â”œâ”€â”€ daily_pv.h5                           # ä»·æ ¼æ•°æ®ï¼ˆ203 MBï¼‰
â””â”€â”€ daily_pv_financial.h5                 # å¤åˆ¶åçš„è´¢åŠ¡æ•°æ®ï¼ˆ1.5 GBï¼‰
```

### ä¸‹ä¸€æ­¥å·¥ä½œ

1. **è¯„ä¼°å™¨å¢å¼º**: å®ç°å¤åˆå› å­è¯„ä¼°å™¨ï¼Œæ·»åŠ äº¤äº’æ•ˆåº”å’Œè¡Œä¸šä¸­æ€§è¯„ä¼°
2. **æ€§èƒ½å¯¹æ¯”**: è¿è¡ŒRD-Agentï¼Œå¯¹æ¯”æ–°æ—§å› å­çš„ICè¡¨ç°
3. **å‚æ•°è°ƒä¼˜**: æ ¹æ®å›æµ‹ç»“æœä¼˜åŒ–å› å­æƒé‡å’Œç»„åˆç­–ç•¥

---

*æœ€åæ›´æ–°ï¼š2025-12-30*
