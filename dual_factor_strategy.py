"""
åŒå› å­é€‰è‚¡ç­–ç•¥ - å®Œå…¨ä¿®å¤ç‰ˆ

åŸºäºQlibæºç åˆ†æçš„ä¿®å¤:
1. $amountæ˜¯Qlibæ ‡å‡†å­—æ®µï¼Œå¯ç›´æ¥ä½¿ç”¨
2. D.instruments()è¿”å›é…ç½®å­—å…¸ï¼ŒD.features()ä¼šè‡ªåŠ¨è¿‡æ»¤æœ‰æ•ˆè‚¡ç¥¨
3. æ—¥æœŸèŒƒå›´ä½¿ç”¨æ­£ç¡®çš„è¾¹ç•Œå¤„ç†
"""

import pandas as pd
import numpy as np
import xgboost as xgb
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')


def get_qlib_data(market='csi300', start_date='2024-01-01', end_date=None):
    """
    ä»Qlibè·å–æ•°æ® - å®Œå…¨ä¿®å¤ç‰ˆ

    ä¿®å¤è¦ç‚¹:
    1. $amountæ˜¯Qlibæ ‡å‡†å­—æ®µï¼Œå¯ç›´æ¥ä½¿ç”¨
    2. D.features()ä¼šè‡ªåŠ¨æ ¹æ®instrumentsé…ç½®è¿‡æ»¤æœ‰æ•ˆè‚¡ç¥¨
    3. ä½¿ç”¨æ—¥é¢‘æ•°æ®ï¼Œend_dateè‡ªåŠ¨ä½¿ç”¨æœ€åä¸€ä¸ªäº¤æ˜“æ—¥
    """
    import qlib
    from qlib.data import D

    # åˆå§‹åŒ–Qlib
    qlib.init(provider_uri='~/.qlib/qlib_data/cn_data', region='cn')

    # è®¾ç½®ç»“æŸæ—¥æœŸ
    if end_date is None:
        # ä½¿ç”¨æ—¥å†çš„æœ€åä¸€ä¸ªäº¤æ˜“æ—¥
        cal = D.calendar(freq='day')
        end_date = pd.Timestamp(cal[-1]).strftime('%Y-%m-%d')
    else:
        # éªŒè¯æ—¥æœŸ
        try:
            end_dt = pd.Timestamp(end_date)
            cal = D.calendar(freq='day')
            cal_last = pd.Timestamp(cal[-1])
            if end_dt > cal_last:
                end_date = cal_last.strftime('%Y-%m-%d')
                print(f"  âš ï¸  ä¿®æ­£ç»“æŸæ—¥æœŸåˆ°æœ€åäº¤æ˜“æ—¥: {end_date}")
        except Exception as e:
            print(f"  âš ï¸  æ—¥æœŸå¤„ç†é”™è¯¯: {e}")

    print(f"  âœ“ è‚¡ç¥¨æ± : {market.upper()}")
    print(f"  âœ“ æŸ¥è¯¢èŒƒå›´: {start_date} è‡³ {end_date}")

    # è·å–instrumentsé…ç½®ï¼ˆæ³¨æ„ï¼šè¿™æ˜¯é…ç½®å­—å…¸ï¼Œä¸æ˜¯è‚¡ç¥¨åˆ—è¡¨ï¼‰
    instruments = D.instruments(market=market)
    print(f"  âœ“ Instrumentsé…ç½®ç±»å‹: {type(instruments)}")

    # æ ‡å‡†å­—æ®µï¼ˆ$amountæ˜¯Qlibæ ‡å‡†å­—æ®µï¼‰
    fields = ['$open', '$high', '$low', '$close', '$volume', '$amount']

    # ä½¿ç”¨D.featuresè·å–æ•°æ®ï¼ˆä¼šè‡ªåŠ¨è¿‡æ»¤æœ‰æ•ˆè‚¡ç¥¨ï¼‰
    print(f"  âœ“ è·å–æ•°æ®...")
    df = D.features(
        instruments=instruments,
        fields=fields,
        start_time=start_date,
        end_time=end_date,
        freq='day'
    )
    df.columns = fields
    df = df.reset_index()

    print(f"  âœ“ æ•°æ®æ—¶é—´èŒƒå›´: {df['datetime'].min()} è‡³ {df['datetime'].max()}")
    print(f"  âœ“ æ•°æ®é‡: {len(df)} è¡Œ")
    print(f"  âœ“ è‚¡ç¥¨æ•°é‡: {df['instrument'].nunique()} åª")
    print(f"  âœ“ æ•°æ®åˆ—: {df.columns.tolist()}")

    return df


# ==================== å› å­1: æ»šåŠ¨å²­å›å½’å› å­ ====================

def calculate_feature_VAM_15(df):
    """
    ç‰¹å¾1: VAM_15 - 15æ—¥æ³¢åŠ¨ç‡è°ƒæ•´åŠ¨é‡
    å…¬å¼: VAM_{15} = M_{15} / Ïƒ_{15}
    """
    print("  - è®¡ç®— VAM_15 (15æ—¥æ³¢åŠ¨ç‡è°ƒæ•´åŠ¨é‡)...")

    df['daily_return'] = df.groupby('instrument')['$close'].transform(
        lambda x: x.pct_change(periods=1)
    )
    df['momentum_15'] = df.groupby('instrument')['$close'].transform(
        lambda x: x.pct_change(periods=15)
    )
    df['volatility_15'] = df.groupby('instrument')['daily_return'].transform(
        lambda x: x.rolling(window=15, min_periods=15).std()
    )
    df['VAM_15'] = df['momentum_15'] / df['volatility_15'].replace(0, np.nan)

    return df


def calculate_feature_VSVN_5_20(df):
    """
    ç‰¹å¾2: VSVN_5_20 - 5æ—¥æˆäº¤é‡æ¿€å˜å½’ä¸€åŒ–
    å…¬å¼: VSVN_{5,20} = (Volume_t / MA_5(Volume_{t-5:t-1})) / Ïƒ_Volume,20
    """
    print("  - è®¡ç®— VSVN_5_20 (æˆäº¤é‡æ¿€å˜å½’ä¸€åŒ–)...")

    df['volume_ma_5'] = df.groupby('instrument')['$volume'].transform(
        lambda x: x.shift(1).rolling(window=5, min_periods=1).mean()
    )
    df['volume_surge'] = df['$volume'] / df['volume_ma_5'].replace(0, np.nan)
    df['volume_volatility_20'] = df.groupby('instrument')['$volume'].transform(
        lambda x: x.rolling(window=20, min_periods=20).std()
    )
    df['VSVN_5_20'] = df['volume_surge'] / df['volume_volatility_20'].replace(0, np.nan)

    return df


def calculate_feature_DDM_20(df):
    """
    ç‰¹å¾3: DDM_20 - 20æ—¥ä¸‹è¡Œåå·®è°ƒæ•´åŠ¨é‡
    å…¬å¼: DDM_{20} = M_{20} / DD_{20}
    """
    print("  - è®¡ç®— DDM_20 (20æ—¥ä¸‹è¡Œåå·®è°ƒæ•´åŠ¨é‡)...")

    df['momentum_20'] = df.groupby('instrument')['$close'].transform(
        lambda x: x.pct_change(periods=20)
    )
    df['daily_return'] = df.groupby('instrument')['$close'].transform(
        lambda x: x.pct_change()
    )

    def downside_deviation(returns):
        negative_returns = returns[returns < 0]
        if len(negative_returns) == 0:
            return np.nan
        return np.sqrt((negative_returns ** 2).mean())

    df['downside_deviation_20'] = df.groupby('instrument')['daily_return'].transform(
        lambda x: x.rolling(window=20, min_periods=20).apply(downside_deviation)
    )
    df['DDM_20'] = df['momentum_20'] / df['downside_deviation_20'].replace(0, np.nan)

    return df


def calculate_feature_RSI_10(df):
    """
    ç‰¹å¾4: RSI_10 - 10æ—¥ç›¸å¯¹å¼ºå¼±æŒ‡æ ‡
    å…¬å¼: RSI_{10} = 100 - 100 / (1 + RS)
    """
    print("  - è®¡ç®— RSI_10 (10æ—¥ç›¸å¯¹å¼ºå¼±æŒ‡æ ‡)...")

    df['price_change'] = df.groupby('instrument')['$close'].transform(lambda x: x.diff())
    df['gain'] = df['price_change'].apply(lambda x: x if x > 0 else 0)
    df['loss'] = df['price_change'].apply(lambda x: -x if x < 0 else 0)
    df['avg_gain_10'] = df.groupby('instrument')['gain'].transform(
        lambda x: x.rolling(window=10, min_periods=10).mean()
    )
    df['avg_loss_10'] = df.groupby('instrument')['loss'].transform(
        lambda x: x.rolling(window=10, min_periods=10).mean()
    )
    df['RS'] = df['avg_gain_10'] / df['avg_loss_10'].replace(0, np.nan)
    df['RSI_10'] = 100 - 100 / (1 + df['RS'])

    return df


def calculate_ridge_regression_factor(df, lambda_reg=0.1, window=60):
    """
    æ»šåŠ¨å²­å›å½’å› å­ï¼ˆå¹´åŒ–æ”¶ç›Š13.31%ï¼‰

    å…¬å¼:
        F_t = Î²_{0,t} + Î²_{1,t}Ã—VAM_{15,t} + Î²_{2,t}Ã—VSVN_{5,20,t} + Î²_{3,t}Ã—DDM_{20,t} + Î²_{4,t}Ã—RSI_{10,t}

        å…¶ä¸­ Î²_t é€šè¿‡å²­å›å½’ä¼°è®¡:
        Î²_t = (X'X + Î»I)^(-1) X'Y
    """
    print("\nğŸ§® è®¡ç®—å²­å›å½’å› å­...")

    df_reset = df.copy()
    df_reset = df_reset.sort_values(['instrument', 'datetime'])

    # è®¡ç®—å››ä¸ªç‰¹å¾
    df_reset = calculate_feature_VAM_15(df_reset)
    df_reset = calculate_feature_VSVN_5_20(df_reset)
    df_reset = calculate_feature_DDM_20(df_reset)
    df_reset = calculate_feature_RSI_10(df_reset)

    # ç›®æ ‡å˜é‡ï¼šæ¬¡æ—¥æ”¶ç›Šç‡
    df_reset['next_day_return'] = df_reset.groupby('instrument')['$close'].transform(
        lambda x: x.pct_change().shift(-1)
    )

    features = ['VAM_15', 'VSVN_5_20', 'DDM_20', 'RSI_10']
    print(f"  - æ‰§è¡Œæ»šåŠ¨å²­å›å½’ (çª—å£={window}å¤©, Î»={lambda_reg})...")

    def rolling_ridge_regression(group):
        group = group.copy()
        group['Ridge_Factor'] = np.nan

        for i in range(window, len(group)):
            X = group[features].iloc[i-window:i].values
            Y = group['next_day_return'].iloc[i-window:i].values

            valid_mask = ~np.isnan(X).any(axis=1) & ~np.isnan(Y)
            X_valid = X[valid_mask]
            Y_valid = Y[valid_mask]

            if len(X_valid) >= 20:
                X_with_intercept = np.column_stack([np.ones(len(X_valid)), X_valid])
                try:
                    XtX = X_with_intercept.T @ X_with_intercept
                    reg_matrix = lambda_reg * np.eye(XtX.shape[0])
                    beta = np.linalg.inv(XtX + reg_matrix) @ X_with_intercept.T @ Y_valid

                    current_features = group[features].iloc[i].values
                    current_with_intercept = np.concatenate([[1], current_features])
                    factor_value = current_with_intercept @ beta
                    group.iloc[i, group.columns.get_loc('Ridge_Factor')] = factor_value
                except:
                    continue

        return group

    df_reset = df_reset.groupby('instrument', group_keys=False).apply(rolling_ridge_regression)
    return df_reset[['datetime', 'instrument', 'Ridge_Factor']]


# ==================== å› å­2: XGBoostæ³¢åŠ¨ç‡åˆ¶åº¦å› å­ ====================

def calculate_xgboost_volatility_factor(df, max_depth=6, learning_rate=0.1, n_estimators=100):
    """
    XGBoostæ³¢åŠ¨ç‡åˆ¶åº¦å› å­ï¼ˆå¹´åŒ–æ”¶ç›Š13.12%ï¼‰

    æ–¹æ³•:
        1. è®¡ç®—æ—¥å†…æ³¢åŠ¨ç‡ = High - Low
        2. è®¡ç®—è¿‡å»20æ—¥æ³¢åŠ¨ç‡ä¸­ä½æ•°ä½œä¸ºåŸºå‡†
        3. è®¡ç®—æœªæ¥5æ—¥å¹³å‡æ³¢åŠ¨ç‡ä½œä¸ºç›®æ ‡
        4. æ„é€ 30ä¸ªæ»åç‰¹å¾ï¼ˆä»·æ ¼ã€æˆäº¤é‡ã€åŠ¨é‡å„10ä¸ªæ»åï¼‰
        5. è®­ç»ƒXGBooståˆ†ç±»å™¨é¢„æµ‹é«˜/ä½æ³¢åŠ¨ç‡åˆ¶åº¦
        6. è¾“å‡ºé«˜æ³¢åŠ¨ç‡åˆ¶åº¦æ¦‚ç‡ä½œä¸ºå› å­å€¼
    """
    print("\nğŸ§® è®¡ç®—XGBoostæ³¢åŠ¨ç‡åˆ¶åº¦å› å­...")

    df_reset = df.copy()
    df_reset = df_reset.sort_values(['instrument', 'datetime'])

    df_reset['daily_range'] = df_reset['$high'] - df_reset['$low']
    df_reset['daily_momentum'] = df_reset.groupby('instrument')['$close'].transform(
        lambda x: x.pct_change()
    )

    df_reset['range_median_20d'] = df_reset.groupby('instrument')['daily_range'].transform(
        lambda x: x.rolling(window=20, min_periods=20).median()
    )

    df_reset['range_avg_next_5d'] = df_reset.groupby('instrument')['daily_range'].transform(
        lambda x: x.shift(-5).rolling(window=5, min_periods=5).mean()
    )

    df_reset['target'] = (df_reset['range_avg_next_5d'] > df_reset['range_median_20d']).astype(int)

    print("  - æ„é€ æ»åç‰¹å¾ (10ä¸ªæ»å Ã— 3ä¸ªå˜é‡ = 30ä¸ªç‰¹å¾)...")
    feature_cols = []

    for lag in range(1, 11):
        df_reset[f'range_lag_{lag}'] = df_reset.groupby('instrument')['daily_range'].transform(
            lambda x: x.shift(lag)
        )
        df_reset[f'volume_lag_{lag}'] = df_reset.groupby('instrument')['$volume'].transform(
            lambda x: x.shift(lag)
        )
        df_reset[f'momentum_lag_{lag}'] = df_reset.groupby('instrument')['daily_momentum'].transform(
            lambda x: x.shift(lag)
        )
        feature_cols.extend([f'range_lag_{lag}', f'volume_lag_{lag}', f'momentum_lag_{lag}'])

    df_features = df_reset.dropna(subset=feature_cols + ['target']).copy()
    df_features = df_features.sort_values('datetime')

    if len(df_features) == 0:
        print("  âœ— æ²¡æœ‰æœ‰æ•ˆæ•°æ®")
        return pd.DataFrame(columns=['datetime', 'instrument', 'XGBoost_Factor'])

    unique_dates = sorted(df_features['datetime'].unique())
    split_idx = int(len(unique_dates) * 0.7)
    train_dates = set(unique_dates[:split_idx])

    train_mask = df_features['datetime'].isin(train_dates)
    X_train = df_features[train_mask][feature_cols]
    y_train = df_features[train_mask]['target']

    print(f"  - è®­ç»ƒé›†: {len(X_train)} æ ·æœ¬")
    print(f"  - è®­ç»ƒXGBoostæ¨¡å‹...")
    model = xgb.XGBClassifier(
        max_depth=max_depth,
        learning_rate=learning_rate,
        n_estimators=n_estimators,
        random_state=42,
        verbosity=0
    )
    model.fit(X_train, y_train)

    df_all_features = df_reset.dropna(subset=feature_cols).copy()
    if len(df_all_features) > 0:
        X_all = df_all_features[feature_cols]
        df_all_features['XGBoost_Factor'] = model.predict_proba(X_all)[:, 1]
        return df_all_features[['datetime', 'instrument', 'XGBoost_Factor']]

    return pd.DataFrame(columns=['datetime', 'instrument', 'XGBoost_Factor'])


# ==================== å› å­ç»„åˆä¸é€‰è‚¡ ====================

def combine_and_standardize_factors(ridge_df, xgb_df, ridge_weight=0.5, xgb_weight=0.5):
    """åˆå¹¶å¹¶æ ‡å‡†åŒ–å› å­"""
    print("\nğŸ“Š åˆå¹¶å’Œæ ‡å‡†åŒ–å› å­...")

    combined = pd.merge(ridge_df, xgb_df, on=['datetime', 'instrument'], how='inner')
    print(f"  âœ“ åˆå¹¶åæ•°æ®é‡: {len(combined)} è¡Œ")

    combined['Ridge_zscore'] = combined.groupby('datetime')['Ridge_Factor'].transform(
        lambda x: (x - x.mean()) / x.std()
    )
    combined['XGBoost_zscore'] = combined.groupby('datetime')['XGBoost_Factor'].transform(
        lambda x: (x - x.mean()) / x.std()
    )

    combined['Ridge_zscore'] = combined['Ridge_zscore'].replace([np.inf, -np.inf], np.nan).fillna(0)
    combined['XGBoost_zscore'] = combined['XGBoost_zscore'].replace([np.inf, -np.inf], np.nan).fillna(0)

    combined['Combined_Factor'] = (
        combined['Ridge_zscore'] * ridge_weight +
        combined['XGBoost_zscore'] * xgb_weight
    )

    return combined


def select_stocks(combined_df, date, top_n=50, min_zscore=0.5):
    """é€‰è‚¡"""
    date_data = combined_df[combined_df['datetime'] == date].copy()

    if len(date_data) == 0:
        print(f"\nâœ— {date} æ²¡æœ‰æ•°æ®")
        return [], None

    filtered = date_data[date_data['Combined_Factor'] >= min_zscore]

    if len(filtered) == 0:
        filtered = date_data.nlargest(top_n, 'Combined_Factor')
    else:
        filtered = filtered.nlargest(top_n, 'Combined_Factor')

    stocks = filtered['instrument'].tolist()

    print(f"\n{'='*70}")
    print(f"ğŸ“ˆ {date} é€‰è‚¡ç»“æœ (TOP {len(stocks)})")
    print(f"{'='*70}")
    print(f"  è‚¡ç¥¨æ± : {len(date_data)} åª | ç¬¦åˆé˜ˆå€¼: {len(date_data[date_data['Combined_Factor'] >= min_zscore])} åª")

    print(f"\n  å‰20åª:")
    for i, (idx, row) in enumerate(filtered.head(20).iterrows(), 1):
        print(f"  {i:2d}. {row['instrument']:10s} - ç»¼åˆå¾—åˆ†: {row['Combined_Factor']:6.2f} (å²­å›å½’: {row['Ridge_zscore']:5.2f}, XGBoost: {row['XGBoost_zscore']:5.2f})")

    return stocks, filtered


# ==================== ä¸»ç¨‹åº ====================

def main():
    print("="*70)
    print("ğŸ¤– åŒå› å­é€‰è‚¡ç­–ç•¥ï¼ˆå®Œå…¨ä¿®å¤ç‰ˆï¼‰")
    print("="*70)

    # å¸‚åœºé…ç½®
    market = 'all'

    # 1. è·å–æ•°æ®
    print("\nğŸ“¥ æ­¥éª¤ 1/4: è·å–Qlibæ•°æ®...")
    df = get_qlib_data(
        market=market,
        start_date='2024-01-01',
        end_date=None  # è‡ªåŠ¨ä½¿ç”¨æœ€åäº¤æ˜“æ—¥
    )

    # 2. è®¡ç®—å²­å›å½’å› å­
    print("\nğŸ“Š æ­¥éª¤ 2/4: è®¡ç®—å²­å›å½’å› å­...")
    ridge_factor = calculate_ridge_regression_factor(df, lambda_reg=0.1, window=60)

    # 3. è®¡ç®—XGBoostå› å­
    print("\nğŸ“Š æ­¥éª¤ 3/4: è®¡ç®—XGBoostæ³¢åŠ¨ç‡åˆ¶åº¦å› å­...")
    xgb_factor = calculate_xgboost_volatility_factor(df, max_depth=6, learning_rate=0.1, n_estimators=100)

    # 4. åˆå¹¶å› å­
    print("\nğŸ“Š æ­¥éª¤ 4/4: åˆå¹¶å› å­å¹¶é€‰è‚¡...")
    combined = combine_and_standardize_factors(ridge_factor, xgb_factor)

    # ä¿å­˜ç»“æœ
    latest_date = combined['datetime'].max()
    combined.to_csv(f'dual_factor_strategy_{market}_{latest_date.strftime("%Y%m%d")}.csv', index=False)
    print(f"\n  âœ“ å› å­æ•°æ®å·²ä¿å­˜: dual_factor_strategy_{market}_{latest_date.strftime('%Y%m%d')}.csv")

    # é€‰è‚¡
    stocks, details = select_stocks(combined, latest_date, top_n=50, min_zscore=0.5)

    if details is not None:
        details.to_csv(f'stock_selection_{market}_{latest_date.strftime("%Y%m%d")}.csv', index=False)

    print("\n" + "="*70)
    print("âœ… é€‰è‚¡å®Œæˆï¼")
    print("="*70)

    return combined, stocks


if __name__ == '__main__':
    try:
        main()
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
