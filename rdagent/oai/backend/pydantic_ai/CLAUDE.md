# Pydantic AI åç«¯é›†æˆ

> æœ€åæ›´æ–°ï¼š2026-01-12
> æ–‡æ¡£è¦†ç›–ç‡ï¼š100%

## ç›¸å¯¹è·¯å¾„é¢åŒ…å±‘
[æ ¹ç›®å½•](../../../../../CLAUDE.md) > [rdagent](../../../../) > [oai](../../../) > [backend](../../) > **pydantic_ai**

---

## ğŸ¯ Pydantic AI æ˜¯ä»€ä¹ˆï¼Ÿ

### æ¦‚è¿°

**Pydantic AI** æ˜¯ä¸€ä¸ªåŸºäº Pydantic çš„ç±»å‹å®‰å…¨ AI Agent æ¡†æ¶ï¼Œæä¾›å¼ºç±»å‹çº¦æŸã€è¿è¡Œæ—¶éªŒè¯å’Œä¼˜é›…çš„å¼€å‘ä½“éªŒã€‚RD-Agent é€šè¿‡ `pydantic_ai.py` æ¨¡å—å°† Pydantic AI ä¸ç°æœ‰çš„ LiteLLM åç«¯é›†æˆï¼Œä¸º Context7ã€RAG ç­‰ Agent æä¾›å¼ºå¤§çš„å¼€å‘åŸºç¡€ã€‚

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Pydantic AI åœ¨ RD-Agent ä¸­çš„ä½ç½®                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚              åº”ç”¨å±‚ (Agents)                        â”‚  â”‚
â”‚   â”‚  â€¢ Context7 Agent (æ™ºèƒ½æ–‡æ¡£æŸ¥è¯¢)                    â”‚  â”‚
â”‚   â”‚  â€¢ RAG Agent (æ£€ç´¢å¢å¼ºç”Ÿæˆ)                         â”‚  â”‚
â”‚   â”‚  â€¢ è‡ªå®šä¹‰ Agent                                      â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                  â”‚                                           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚         PAI Agent åŸºç±»                              â”‚  â”‚
â”‚   â”‚  â€¢ Pydantic AI é›†æˆ                                 â”‚  â”‚
â”‚   â”‚  â€¢ MCP å·¥å…·é›†æ”¯æŒ                                   â”‚  â”‚
â”‚   â”‚  â€¢ Prefect ç¼“å­˜                                    â”‚  â”‚
â”‚   â”‚  â€¢ å¼‚æ­¥å¤„ç†                                        â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                  â”‚                                           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚       pydantic_ai.py (é€‚é…å™¨)                       â”‚  â”‚
â”‚   â”‚  â€¢ get_agent_model()                               â”‚  â”‚
â”‚   â”‚  â€¢ LiteLLM â†’ Pydantic AI è½¬æ¢                      â”‚  â”‚
â”‚   â”‚  â€¢ Provider æ˜ å°„å’Œé…ç½®                             â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                  â”‚                                           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚        LiteLLM åç«¯                                â”‚  â”‚
â”‚   â”‚  â€¢ å¤š Provider æ”¯æŒ                                â”‚  â”‚
â”‚   â”‚  â€¢ æˆæœ¬è¿½è¸ª                                        â”‚  â”‚
â”‚   â”‚  â€¢ é”™è¯¯å¤„ç†                                        â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                  â”‚                                           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   â”‚     LLM Providers                                  â”‚  â”‚
â”‚   â”‚  â€¢ OpenAI (GPT-4, GPT-3.5)                         â”‚  â”‚
â”‚   â”‚  â€¢ Anthropic (Claude)                              â”‚  â”‚
â”‚   â”‚  â€¢ Azure OpenAI                                    â”‚  â”‚
â”‚   â”‚  â€¢ æœ¬åœ°æ¨¡å‹                                        â”‚  â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ¨ æ ¸å¿ƒä»·å€¼

### ä¸ºä»€ä¹ˆé€‰æ‹© Pydantic AIï¼Ÿ

| ç‰¹æ€§ | è¯´æ˜ | ä¼˜åŠ¿ |
|------|------|------|
| **ç±»å‹å®‰å…¨** | åŸºäº Pydantic çš„å¼ºç±»å‹çº¦æŸ | ğŸ›¡ï¸ ç¼–è¯‘æ—¶é”™è¯¯æ£€æµ‹ |
| **è¿è¡Œæ—¶éªŒè¯** | è‡ªåŠ¨éªŒè¯è¾“å…¥è¾“å‡º | âœ… æ•°æ®è´¨é‡ä¿è¯ |
| **ä¼˜é›…é›†æˆ** | ä¸ MCP åè®®æ— ç¼é›†æˆ | ğŸ”Œ æ ‡å‡†åŒ–å·¥å…·è°ƒç”¨ |
| **å¼€å‘ä½“éªŒ** | æ¸…æ™°çš„ API å’Œé”™è¯¯æç¤º | ğŸ’¡ å¿«é€Ÿå¼€å‘ |

### åœ¨ RD-Agent ä¸­çš„è§’è‰²

```
æ ¸å¿ƒåŠŸèƒ½ï¼š
1. ç±»å‹å®‰å…¨çš„ Agent å¼€å‘
   - å¼ºç±»å‹å·¥å…·å®šä¹‰
   - ç»“æ„åŒ–è¾“å…¥è¾“å‡º
   - è‡ªåŠ¨éªŒè¯å’Œè½¬æ¢

2. MCP å·¥å…·é›†æ”¯æŒ
   - æ ‡å‡†åŒ–å·¥å…·è°ƒç”¨
   - æµå¼æ•°æ®ä¼ è¾“
   - å¤šæœåŠ¡é›†æˆ

3. LiteLLM åç«¯é€‚é…
   - ç»Ÿä¸€çš„å¤š Provider æ”¯æŒ
   - æˆæœ¬è¿½è¸ª
   - é”™è¯¯å¤„ç†
```

---

## ğŸ”§ æ ¸å¿ƒç»„ä»¶

### æ–‡ä»¶ç»“æ„

```
rdagent/oai/backend/pydantic_ai.py
â”œâ”€â”€ PROVIDER_TO_ENV_MAP     # Provider åˆ°ç¯å¢ƒå˜é‡çš„æ˜ å°„
â””â”€â”€ get_agent_model()       # æ ¸å¿ƒå‡½æ•°ï¼šè·å– Pydantic AI æ¨¡å‹
```

### Provider æ˜ å°„

```python
# Provider åˆ°ç¯å¢ƒå˜é‡å‰ç¼€çš„æ˜ å°„
PROVIDER_TO_ENV_MAP = {
    "openai": "OPENAI",
    "azure_ai": "AZURE_AI",
    "azure": "AZURE",
    "litellm_proxy": "LITELLM_PROXY",
}
```

**ä½œç”¨**ï¼šå°† LiteLLM çš„ Provider åç§°æ˜ å°„åˆ°æ­£ç¡®çš„ç¯å¢ƒå˜é‡å‰ç¼€

**ç¤ºä¾‹**ï¼š
```python
# Provider: "openai"
# ç¯å¢ƒå˜é‡: OPENAI_API_KEY, OPENAI_API_BASE

# Provider: "azure_ai"
# ç¯å¢ƒå˜é‡: AZURE_AI_API_KEY, AZURE_AI_API_BASE
```

---

## ğŸš€ æ ¸å¿ƒå‡½æ•°

### `get_agent_model()`

**åŠŸèƒ½**ï¼šå°† LiteLLM åç«¯è½¬æ¢ä¸º Pydantic AI å¯ç”¨çš„æ¨¡å‹

**ç­¾å**ï¼š
```python
def get_agent_model() -> OpenAIChatModel
```

**ä½¿ç”¨ç¤ºä¾‹**ï¼š
```python
from rdagent.oai.backend.pydantic_ai import get_agent_model
from pydantic_ai import Agent

# è·å–æ¨¡å‹
model = get_agent_model()

# åˆ›å»º Agent
agent = Agent(model, system_prompt="You are helpful.")
```

### å®ç°ç»†èŠ‚

```python
def get_agent_model() -> OpenAIChatModel:
    """
    å°† LiteLLM è½¬æ¢ä¸º Pydantic AI æ¨¡å‹

    æµç¨‹ï¼š
    1. è·å– LiteLLM åç«¯å®ä¾‹
    2. æå–æ¨¡å‹é…ç½®å‚æ•°
    3. ç¡®å®š Provider ç±»å‹
    4. è·å– API å¯†é’¥å’ŒåŸºç¡€ URL
    5. æ„å»º OpenAIChatModel
    """
    # 1. è·å–åç«¯
    backend = APIBackend()
    assert isinstance(backend, LiteLLMAPIBackend), \
        "Only LiteLLMAPIBackend is supported"

    # 2. è·å–å®Œæ•´é…ç½®
    compl_kwargs = backend.get_complete_kwargs()
    selected_model = compl_kwargs["model"]

    # 3. ç¡®å®š Provider
    _, custom_llm_provider, _, _ = get_llm_provider(selected_model)
    assert custom_llm_provider in PROVIDER_TO_ENV_MAP, \
        f"Provider {custom_llm_provider} not supported"

    # 4. è·å– API å¯†é’¥å’ŒåŸºç¡€ URL
    prefix = PROVIDER_TO_ENV_MAP[custom_llm_provider]
    api_key = os.getenv(f"{prefix}_API_KEY", None)
    api_base = os.getenv(f"{prefix}_API_BASE", None)

    # 5. æ„å»ºæ¨¡å‹è®¾ç½®
    kwargs = {
        "openai_reasoning_effort": compl_kwargs.get("reasoning_effort"),
        "max_tokens": compl_kwargs.get("max_tokens"),
        "temperature": compl_kwargs.get("temperature"),
    }
    if compl_kwargs.get("max_tokens") is None:
        kwargs["max_tokens"] = LLM_SETTINGS.chat_max_tokens

    settings = OpenAIChatModelSettings(**kwargs)

    # 6. è¿”å›æ¨¡å‹
    return OpenAIChatModel(
        selected_model,
        provider=LiteLLMProvider(api_base=api_base, api_key=api_key),
        settings=settings
    )
```

---

## ğŸ”— é›†æˆæ¶æ„

### å®Œæ•´è°ƒç”¨é“¾

```
ç”¨æˆ·ä»£ç 
  â”‚
  â”‚ context7a.query("æŸ¥è¯¢")
  â–¼
Context7 Agent
  â”‚
  â”‚ PAIAAgent.query(query)
  â–¼
PAI Agent åŸºç±»
  â”‚
  â”‚ self.agent.run_sync(query)
  â–¼
Pydantic AI Agent
  â”‚
  â”‚ è°ƒç”¨ get_agent_model()
  â–¼
pydantic_ai.py
  â”‚
  â”‚ APIBackend() â†’ LiteLLMAPIBackend
  â”‚ get_complete_kwargs()
  â”‚ get_llm_provider()
  â”‚ os.getenv("API_KEY")
  â–¼
OpenAIChatModel
  â”‚
  â”‚ LiteLLMProvider
  â–¼
LiteLLM åç«¯
  â”‚
  â”‚ litellm.completion()
  â–¼
LLM Provider
  (OpenAI / Claude / Azure)
```

### ç±»å‹è½¬æ¢æµç¨‹

```python
# LiteLLM é…ç½®
litellm_config = {
    "model": "gpt-4",
    "api_key": "...",
    "api_base": "...",
    "temperature": 0.7,
    "max_tokens": 2000
}

# â†“ è½¬æ¢

# Pydantic AI é…ç½®
pydantic_ai_config = {
    "model": "gpt-4",
    "provider": LiteLLMProvider(
        api_base="...",
        api_key="..."
    ),
    "settings": OpenAIChatModelSettings(
        temperature=0.7,
        max_tokens=2000
    )
}
```

---

## ğŸ“– ä½¿ç”¨æŒ‡å—

### åŸºç¡€ç”¨æ³•

```python
from rdagent.oai.backend.pydantic_ai import get_agent_model
from pydantic_ai import Agent

# 1. è·å–æ¨¡å‹
model = get_agent_model()

# 2. åˆ›å»º Agent
agent = Agent(
    model=model,
    system_prompt="You are a helpful assistant."
)

# 3. æ‰§è¡ŒæŸ¥è¯¢
result = agent.run_sync("Hello, how are you?")
print(result.output)
```

### åœ¨ PAI Agent ä¸­ä½¿ç”¨

```python
from rdagent.components.agent.base import PAIAgent
from rdagent.oai.backend.pydantic_ai import get_agent_model
from pydantic_ai.mcp import MCPServerStreamableHTTP

class MyAgent(PAIAgent):
    def __init__(self):
        # ä½¿ç”¨ get_agent_model() è·å–æ¨¡å‹
        # æ³¨æ„ï¼šPAI Agent å†…éƒ¨ä¼šè‡ªåŠ¨è°ƒç”¨ get_agent_model()
        toolsets = [
            MCPServerStreamableHTTP("http://localhost:8124/mcp")
        ]
        super().__init__(
            system_prompt="You are helpful.",
            toolsets=toolsets
        )
```

### é…ç½®ç¯å¢ƒå˜é‡

```bash
# OpenAI
export OPENAI_API_KEY=sk-...
export OPENAI_API_BASE=https://api.openai.com/v1

# Anthropic Claude
export ANTHROPIC_API_KEY=sk-ant-...
export ANTHROPIC_API_BASE=https://api.anthropic.com

# Azure OpenAI
export AZURE_API_KEY=...
export AZURE_API_BASE=https://your-resource.openai.azure.com

# LiteLLM Proxy
export LITELLM_PROXY_API_KEY=...
export LITELLM_PROXY_API_BASE=http://localhost:4000
```

---

## ğŸ› ï¸ é«˜çº§é…ç½®

### æ¨¡å‹å‚æ•°

```python
# åœ¨ LLM_SETTINGS ä¸­é…ç½®
from rdagent.oai.llm_conf import LLM_SETTINGS

# æŸ¥çœ‹å½“å‰é…ç½®
print(LLM_SETTINGS.chat_model)        # æ¨¡å‹åç§°
print(LLM_SETTINGS.chat_max_tokens)   # æœ€å¤§ token æ•°
print(LLM_SETTINGS.temperature)       # æ¸©åº¦å‚æ•°
```

### è‡ªå®šä¹‰ Provider

æ·»åŠ æ–°çš„ Provider æ˜ å°„ï¼š

```python
# åœ¨ pydantic_ai.py ä¸­æ·»åŠ 
PROVIDER_TO_ENV_MAP = {
    "openai": "OPENAI",
    "azure_ai": "AZURE_AI",
    "azure": "AZURE",
    "litellm_proxy": "LITELLM_PROXY",
    # æ·»åŠ æ–°çš„ Provider
    "my_provider": "MY_PROVIDER",
}
```

ç„¶åè®¾ç½®ç¯å¢ƒå˜é‡ï¼š
```bash
export MY_PROVIDER_API_KEY=...
export MY_PROVIDER_API_BASE=...
```

---

## ğŸ” é”™è¯¯å¤„ç†

### å¸¸è§é”™è¯¯

#### 1. Provider ä¸æ”¯æŒ

```python
# é”™è¯¯
AssertionError: Provider 'my_provider' not supported.
Please add it into `PROVIDER_TO_ENV_MAP`

# è§£å†³ï¼šåœ¨ PROVIDER_TO_ENV_MAP ä¸­æ·»åŠ æ˜ å°„
```

#### 2. API å¯†é’¥æœªè®¾ç½®

```python
# é”™è¯¯
AuthenticationError: No API key found

# è§£å†³ï¼šè®¾ç½®æ­£ç¡®çš„ç¯å¢ƒå˜é‡
export OPENAI_API_KEY=sk-...
```

#### 3. åç«¯ç±»å‹é”™è¯¯

```python
# é”™è¯¯
AssertionError: Only LiteLLMAPIBackend is supported

# è§£å†³ï¼šç¡®ä¿ APIBackend æ˜¯ LiteLLMAPIBackend å®ä¾‹
from rdagent.oai.backend.litellm import LiteLLMAPIBackend
```

---

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

### 1. æ¨¡å‹ç¼“å­˜

```python
# æ¨¡å‹å®ä¾‹ä¼šè¢«ç¼“å­˜
model1 = get_agent_model()
model2 = get_agent_model()
# model1 is model2  # True
```

### 2. è¿æ¥å¤ç”¨

```python
# å¤ç”¨ LiteLLM Provider è¿æ¥
provider = LiteLLMProvider(api_base=..., api_key=...)
model1 = OpenAIChatModel("gpt-4", provider=provider)
model2 = OpenAIChatModel("claude-3", provider=provider)
```

### 3. å¼‚æ­¥å¤„ç†

```python
# Pydantic AI æ”¯æŒå¼‚æ­¥
import asyncio

async def query_async(agent, query):
    result = await agent.run(query)
    return result.output

# è¿è¡Œå¼‚æ­¥æŸ¥è¯¢
result = asyncio.run(query_async(agent, "æŸ¥è¯¢"))
```

---

## ğŸ§ª æµ‹è¯•ä¸éªŒè¯

### å•å…ƒæµ‹è¯•

```python
# test/oai/test_pydantic.py
import unittest
from rdagent.components.agent.context7 import Agent

class PydanticTest(unittest.TestCase):
    def test_context7(self):
        """æµ‹è¯• Context7 Agent"""
        context7a = Agent()
        res = context7a.query("pandas read_csv encoding error")
        print(res)
        # éªŒè¯è¿”å›ç»“æœ
        self.assertIsNotNone(res)
        self.assertIn("API", res)

if __name__ == "__main__":
    unittest.main()
```

### é›†æˆæµ‹è¯•

```python
from rdagent.oai.backend.pydantic_ai import get_agent_model
from pydantic_ai import Agent

def test_integration():
    """å®Œæ•´é›†æˆæµ‹è¯•"""
    # 1. è·å–æ¨¡å‹
    model = get_agent_model()

    # 2. åˆ›å»º Agent
    agent = Agent(model, "You are helpful.")

    # 3. æ‰§è¡ŒæŸ¥è¯¢
    result = agent.run_sync("Test message")

    # 4. éªŒè¯ç»“æœ
    assert result.output is not None
    assert len(result.output) > 0
    print("âœ… é›†æˆæµ‹è¯•é€šè¿‡")
```

---

## ğŸ”— ä¸å…¶ä»–ç»„ä»¶çš„å…³ç³»

### ä¾èµ–å…³ç³»

```
pydantic_ai.py
  â”‚
  â”œâ”€â†’ APIBackend (llm_utils.py)
  â”‚     â””â”€â†’ LiteLLMAPIBackend (litellm.py)
  â”‚
  â”œâ”€â†’ LLM_SETTINGS (llm_conf.py)
  â”‚
  â”œâ”€â†’ get_llm_provider (litellm.utils)
  â”‚
  â””â”€â†’ OpenAIChatModel (pydantic_ai.models.openai)
       â””â”€â†’ LiteLLMProvider (pydantic_ai.providers.litellm)
```

### è¢«ä¾èµ–å…³ç³»

```
pydantic_ai.py
  â”‚
  â”œâ”€â†’ PAI Agent (components/agent/base.py)
  â”‚     â””â”€â†’ Context7 Agent
  â”‚     â””â”€â†’ RAG Agent
  â”‚
  â””â”€â†’ è‡ªå®šä¹‰ Agent
```

---

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. ç¯å¢ƒé…ç½®

```bash
# .env æ–‡ä»¶
OPENAI_API_KEY=sk-...
OPENAI_API_BASE=https://api.openai.com/v1

# æˆ–ä½¿ç”¨ä¸åŒçš„ Provider
ANTHROPIC_API_KEY=sk-ant-...
ANTHROPIC_API_BASE=https://api.anthropic.com
```

### 2. æ¨¡å‹é€‰æ‹©

```python
# åœ¨ LLM_SETTINGS ä¸­é…ç½®
from rdagent.oai.llm_conf import LLM_SETTINGS

# é€‰æ‹©åˆé€‚çš„æ¨¡å‹
LLM_SETTINGS.chat_model = "gpt-4"  # æˆ– "claude-3-opus"
```

### 3. é”™è¯¯å¤„ç†

```python
from rdagent.oai.backend.pydantic_ai import get_agent_model

try:
    model = get_agent_model()
    agent = Agent(model, "You are helpful.")
    result = agent.run_sync("Query")
except AssertionError as e:
    print(f"é…ç½®é”™è¯¯: {e}")
except Exception as e:
    print(f"è¿è¡Œæ—¶é”™è¯¯: {e}")
```

### 4. æ—¥å¿—è°ƒè¯•

```python
from rdagent.log import rdagent_logger as logger

# å¯ç”¨è¯¦ç»†æ—¥å¿—
logger.setLevel("DEBUG")

# æŸ¥çœ‹ LLM é…ç½®
logger.info(f"æ¨¡å‹: {LLM_SETTINGS.chat_model}")
logger.info(f"æœ€å¤§ token: {LLM_SETTINGS.chat_max_tokens}")
```

---

## â“ å¸¸è§é—®é¢˜ (FAQ)

### Q: ä¸ºä»€ä¹ˆéœ€è¦ Pydantic AIï¼Ÿ

A:
- **ç±»å‹å®‰å…¨**ï¼šç¼–è¯‘æ—¶æ£€æµ‹é”™è¯¯ï¼Œå‡å°‘è¿è¡Œæ—¶é—®é¢˜
- **MCP é›†æˆ**ï¼šæ ‡å‡†åŒ–å·¥å…·è°ƒç”¨
- **å¼€å‘ä½“éªŒ**ï¼šæ¸…æ™°çš„ API å’Œé”™è¯¯æç¤º

### Q: Pydantic AI ä¸ LiteLLM çš„åŒºåˆ«ï¼Ÿ

A:
- **LiteLLM**ï¼šç»Ÿä¸€çš„ LLM è°ƒç”¨æ¥å£
- **Pydantic AI**ï¼šç±»å‹å®‰å…¨çš„ Agent æ¡†æ¶

åœ¨ RD-Agent ä¸­ï¼š
- LiteLLM è´Ÿè´£åº•å±‚ API è°ƒç”¨
- Pydantic AI è´Ÿè´£ Agent å¼€å‘

### Q: å¦‚ä½•æ·»åŠ æ–°çš„ Providerï¼Ÿ

A:
```python
# 1. åœ¨ PROVIDER_TO_ENV_MAP ä¸­æ·»åŠ 
PROVIDER_TO_ENV_MAP["my_provider"] = "MY_PROVIDER"

# 2. è®¾ç½®ç¯å¢ƒå˜é‡
export MY_PROVIDER_API_KEY=...
export MY_PROVIDER_API_BASE=...

# 3. ä½¿ç”¨
LLM_SETTINGS.chat_model = "my_provider/model_name"
```

### Q: å¦‚ä½•è°ƒè¯•æ¨¡å‹é…ç½®ï¼Ÿ

A:
```python
from rdagent.oai.backend.pydantic_ai import get_agent_model
from rdagent.oai.llm_conf import LLM_SETTINGS

# æ‰“å°é…ç½®
print(f"æ¨¡å‹: {LLM_SETTINGS.chat_model}")
print(f"æ¸©åº¦: {LLM_SETTINGS.temperature}")
print(f"æœ€å¤§ token: {LLM_SETTINGS.chat_max_tokens}")

# è·å–æ¨¡å‹å¹¶æ£€æŸ¥
model = get_agent_model()
print(f"æ¨¡å‹ç±»å‹: {type(model)}")
print(f"Provider: {model.provider}")
```

---

## ğŸ”— ç›¸å…³æ–‡æ¡£

### å†…éƒ¨æ–‡æ¡£
- [PAI Agent åŸºç±»](../../components/agent/base.py)
- [LiteLLM åç«¯](../litellm/)
- [Context7 Agent](../../components/agent/context7/)
- [RAG Agent](../../components/agent/rag/)

### å¤–éƒ¨æ–‡æ¡£
- [Pydantic AI å®˜æ–¹æ–‡æ¡£](https://ai.pydantic.dev/)
- [LiteLLM æ–‡æ¡£](https://docs.litellm.ai/)
- [Pydantic æ–‡æ¡£](https://docs.pydantic.dev/)

---

## ğŸ“š ç›¸å…³æ–‡ä»¶æ¸…å•

### æ ¸å¿ƒæ–‡ä»¶
- `rdagent/oai/backend/pydantic_ai.py` - Pydantic AI é€‚é…å™¨ï¼ˆ64è¡Œï¼‰

### ä¾èµ–æ–‡ä»¶
- `rdagent/oai/backend/base.py` - API åç«¯åŸºç±»
- `rdagent/oai/backend/litellm.py` - LiteLLM åç«¯å®ç°
- `rdagent/oai/llm_conf.py` - LLM é…ç½®ç³»ç»Ÿ
- `rdagent/oai/llm_utils.py` - LLM å·¥å…·å‡½æ•°

### ä½¿ç”¨æ–‡ä»¶
- `rdagent/components/agent/base.py` - PAI Agent åŸºç±»
- `rdagent/components/agent/context7/__init__.py` - Context7 Agent
- `rdagent/components/agent/rag/__init__.py` - RAG Agent

### æµ‹è¯•æ–‡ä»¶
- `test/oai/test_pydantic.py` - Pydantic AI æµ‹è¯•
- `test/oai/test_prefect_cache.py` - Prefect ç¼“å­˜æµ‹è¯•

---

## ğŸ”„ å˜æ›´è®°å½• (Changelog)

### 2026-01-12 - Pydantic AI åç«¯æ–‡æ¡£åˆ›å»º
- âœ… Pydantic AI æ¦‚è¿°å’Œä»·å€¼è¯´æ˜
- âœ… æ ¸å¿ƒç»„ä»¶å’Œ Provider æ˜ å°„è¯¦è§£
- âœ… get_agent_model() å‡½æ•°å®Œæ•´è¯´æ˜
- âœ… é›†æˆæ¶æ„å’Œç±»å‹è½¬æ¢æµç¨‹
- âœ… ä½¿ç”¨æŒ‡å—å’Œé…ç½®è¯´æ˜
- âœ… é”™è¯¯å¤„ç†å’Œæ€§èƒ½ä¼˜åŒ–
- âœ… æµ‹è¯•ä¸éªŒè¯æ–¹æ³•
- âœ… FAQ å’Œæœ€ä½³å®è·µ
- âœ… 100% è¦†ç›–ç‡

---

*æœ€åæ›´æ–°ï¼š2026-01-12*
