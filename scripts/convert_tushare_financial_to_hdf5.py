#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Tushareè´¢åŠ¡æ•°æ®è½¬æ¢ä¸ºHDF5æ ¼å¼

åŠŸèƒ½ï¼š
1. è¯»å–Tushareä¸‹è½½çš„è´¢åŠ¡æ•°æ®CSVæ–‡ä»¶
2. è½¬æ¢ä¸ºQlibå…¼å®¹çš„MultiIndexæ ¼å¼
3. ç”ŸæˆåŒ…å«è´¢åŠ¡æ•°æ®çš„HDF5æ–‡ä»¶
4. æ”¯æŒå¢žé‡æ›´æ–°

ä½¿ç”¨æ–¹æ³•ï¼š
    python scripts/convert_tushare_financial_to_hdf5.py

ä½œè€…: RD-Agent Team
"""

import pandas as pd
import numpy as np
from pathlib import Path
from typing import List, Optional
import argparse


# æ ¸å¿ƒè´¢åŠ¡æŒ‡æ ‡æ˜ å°„ï¼ˆTushareå­—æ®µå -> Qlibé£Žæ ¼å­—æ®µåï¼‰
FINANCIAL_FIELDS_MAPPING = {
    # ä¼°å€¼æŒ‡æ ‡
    "eps": "EPS",                    # æ¯è‚¡æ”¶ç›Š
    "bps": "BPS",                    # æ¯è‚¡å‡€èµ„äº§
    "ocfps": "OCFPS",                # æ¯è‚¡ç»è¥çŽ°é‡‘æµ
    "cfps": "CFPS",                  # æ¯è‚¡çŽ°é‡‘æµ

    # ç›ˆåˆ©èƒ½åŠ›
    "roe": "ROE",                    # å‡€èµ„äº§æ”¶ç›ŠçŽ‡
    "roa": "ROA",                    # æ€»èµ„äº§æ”¶ç›ŠçŽ‡
    "roic": "ROIC",                  # æŠ•å…¥èµ„æœ¬å›žæŠ¥çŽ‡
    "netprofit_margin": "NetProfitMargin",  # é”€å”®å‡€åˆ©çŽ‡
    "grossprofit_margin": "GrossProfitMargin",  # é”€å”®æ¯›åˆ©çŽ‡

    # æˆé•¿èƒ½åŠ›
    "basic_eps_yoy": "EPS_Growth",   # æ¯è‚¡æ”¶ç›Šå¢žé•¿çŽ‡
    "cfps_yoy": "CFPS_Growth",       # æ¯è‚¡çŽ°é‡‘æµå¢žé•¿çŽ‡
    "netprofit_yoy": "NetProfit_Growth",  # å‡€åˆ©æ¶¦å¢žé•¿çŽ‡
    "op_yoy": "OP_Growth",           # è¥ä¸šåˆ©æ¶¦å¢žé•¿çŽ‡

    # å¿å€ºèƒ½åŠ›
    "debt_to_assets": "DebtToAssets", # èµ„äº§è´Ÿå€ºçŽ‡
    "current_ratio": "CurrentRatio", # æµåŠ¨æ¯”çŽ‡
    "quick_ratio": "QuickRatio",     # é€ŸåŠ¨æ¯”çŽ‡
    "ocf_to_debt": "OCF_To_Debt",    # çŽ°é‡‘æµå€ºåŠ¡æ¯”

    # è¿è¥èƒ½åŠ›
    "assets_turn": "AssetsTurnover", # æ€»èµ„äº§å‘¨è½¬çŽ‡
    "ar_turn": "AR_Turnover",        # åº”æ”¶è´¦æ¬¾å‘¨è½¬çŽ‡
    "ca_turn": "CA_Turnover",        # æµåŠ¨èµ„äº§å‘¨è½¬çŽ‡

    # å…¶ä»–é‡è¦æŒ‡æ ‡
    "ebitda": "EBITDA",              # æ¯ç¨ŽæŠ˜æ—§æ‘Šé”€å‰åˆ©æ¶¦
    "operating_profit": "OperatingProfit",  # è¥ä¸šåˆ©æ¶¦
}


def convert_financial_csv_to_hdf5(
    input_csv: str,
    output_h5: str,
    fields_mapping: Optional[dict] = None,
    min_date: Optional[str] = None,
    max_date: Optional[str] = None,
) -> pd.DataFrame:
    """
    è½¬æ¢Tushareè´¢åŠ¡æ•°æ®CSVä¸ºHDF5æ ¼å¼

    Args:
        input_csv: è¾“å…¥CSVæ–‡ä»¶è·¯å¾„
        output_h5: è¾“å‡ºHDF5æ–‡ä»¶è·¯å¾„
        fields_mapping: å­—æ®µæ˜ å°„å­—å…¸ï¼ŒNoneåˆ™ä½¿ç”¨é»˜è®¤
        min_date: æœ€å°æ—¥æœŸï¼ˆè¿‡æ»¤ï¼‰
        max_date: æœ€å¤§æ—¥æœŸï¼ˆè¿‡æ»¤ï¼‰

    Returns:
        è½¬æ¢åŽçš„DataFrame
    """
    print(f"ðŸ“‚ è¯»å–è´¢åŠ¡æ•°æ®: {input_csv}")

    # è¯»å–CSVæ–‡ä»¶
    df = pd.read_csv(input_csv, encoding='utf-8-sig')

    print(f"  åŽŸå§‹æ•°æ®: {len(df)} è¡Œ Ã— {len(df.columns)} åˆ—")

    # åŸºæœ¬æ•°æ®æ¸…æ´—
    df = df[df['end_date'].notna()].copy()

    # è½¬æ¢è‚¡ç¥¨ä»£ç æ ¼å¼ï¼ˆ000001.SZ -> 000001SZï¼‰
    df['instrument'] = df['ts_code'].str.replace('.', '')

    # è½¬æ¢æ—¥æœŸæ ¼å¼
    df['datetime'] = pd.to_datetime(df['end_date'], format='%Y%m%d')

    # é€‰æ‹©å­—æ®µæ˜ å°„
    if fields_mapping is None:
        fields_mapping = FINANCIAL_FIELDS_MAPPING

    # é€‰æ‹©è¦è½¬æ¢çš„å­—æ®µï¼ˆå­˜åœ¨çš„å­—æ®µï¼‰
    available_fields = {k: v for k, v in fields_mapping.items() if k in df.columns}
    print(f"  å¯ç”¨å­—æ®µ: {len(available_fields)}/{len(fields_mapping)}")
    print(f"  å­—æ®µåˆ—è¡¨: {list(available_fields.values())}")

    # åˆ›å»ºæ–°çš„DataFrameï¼ˆåŒ…å«åŽŸå§‹çš„ts_codeã€end_dateã€ann_dateåˆ—ï¼‰
    base_cols = ['ts_code', 'end_date']
    if 'ann_date' in df.columns:
        base_cols.append('ann_date')
    df_selected = df[base_cols + list(available_fields.keys())].copy()

    # é‡å‘½ååˆ—
    df_selected = df_selected.rename(columns=available_fields)

    # å…ˆåŽ»é‡ï¼ˆåŒä¸€è‚¡ç¥¨åŒä¸€æ—¥æœŸä¿ç•™æœ€æ–°æ•°æ®ï¼‰
    sort_cols = ['ts_code', 'end_date']
    if 'ann_date' in df_selected.columns:
        sort_cols.append('ann_date')
    df_selected = df_selected.sort_values(sort_cols)
    df_selected = df_selected.drop_duplicates(subset=['ts_code', 'end_date'], keep='last')

    # åˆ›å»ºdatetimeåˆ—ï¼ˆç”¨äºŽç´¢å¼•ï¼‰
    df_selected['datetime'] = pd.to_datetime(df_selected['end_date'], format='%Y%m%d')

    # æ—¥æœŸè¿‡æ»¤
    if min_date:
        df_selected = df_selected[df_selected['datetime'] >= min_date]
    if max_date:
        df_selected = df_selected[df_selected['datetime'] <= max_date]

    # è®¾ç½®MultiIndex
    df_result = df_selected.set_index(['datetime', 'ts_code'])
    df_result.index.names = ['datetime', 'instrument']

    # ç§»é™¤å…¨ä¸ºNaNçš„åˆ—
    df_result = df_result.dropna(axis=1, how='all')

    # è½¬æ¢æ•°æ®ç±»åž‹
    for col in df_result.columns:
        df_result[col] = pd.to_numeric(df_result[col], errors='coerce')

    print(f"  è½¬æ¢åŽæ•°æ®: {len(df_result)} è¡Œ Ã— {len(df_result.columns)} åˆ—")
    print(f"  æ—¶é—´èŒƒå›´: {df_result.index.get_level_values(0).min()} è‡³ {df_result.index.get_level_values(0).max()}")
    print(f"  è‚¡ç¥¨æ•°é‡: {df_result.index.get_level_values(1).nunique()}")

    # ä¿å­˜ä¸ºHDF5
    print(f"ðŸ’¾ ä¿å­˜åˆ°: {output_h5}")
    df_result.to_hdf(output_h5, key='data', mode='w')

    print(f"âœ… è½¬æ¢å®Œæˆï¼")
    print(f"  æ–‡ä»¶å¤§å°: {Path(output_h5).stat().st_size / 1024 / 1024:.2f} MB")

    return df_result


def merge_financial_with_price(
    financial_h5: str,
    price_h5: str,
    output_h5: str,
):
    """
    åˆå¹¶è´¢åŠ¡æ•°æ®å’Œä»·æ ¼æ•°æ®

    Args:
        financial_h5: è´¢åŠ¡æ•°æ®HDF5æ–‡ä»¶
        price_h5: ä»·æ ¼æ•°æ®HDF5æ–‡ä»¶
        output_h5: è¾“å‡ºåˆå¹¶åŽçš„HDF5æ–‡ä»¶
    """
    print("\nðŸ“Š åˆå¹¶è´¢åŠ¡æ•°æ®å’Œä»·æ ¼æ•°æ®...")

    # è¯»å–æ•°æ®
    df_financial = pd.read_hdf(financial_h5, key='data')
    df_price = pd.read_hdf(price_h5, key='data')

    print(f"  è´¢åŠ¡æ•°æ®: {len(df_financial)} è¡Œ Ã— {len(df_financial.columns)} åˆ—")
    print(f"  ä»·æ ¼æ•°æ®: {len(df_price)} è¡Œ Ã— {len(df_price.columns)} åˆ—")

    # åˆå¹¶æ•°æ®ï¼ˆä¿ç•™æ‰€æœ‰åˆ—ï¼‰
    df_merged = df_price.join(df_financial, how='left')

    # ç»Ÿè®¡åˆå¹¶æƒ…å†µ
    financial_cols = set(df_financial.columns)
    price_cols = set(df_price.columns)

    print(f"  åˆå¹¶åŽæ•°æ®: {len(df_merged)} è¡Œ Ã— {len(df_merged.columns)} åˆ—")
    print(f"  ä»·æ ¼å­—æ®µ: {len(price_cols)} ä¸ª")
    print(f"  è´¢åŠ¡å­—æ®µ: {len(financial_cols)} ä¸ª")

    # ç»Ÿè®¡è´¢åŠ¡å­—æ®µçš„è¦†ç›–çŽ‡
    for col in financial_cols:
        coverage = df_merged[col].notna().sum() / len(df_merged) * 100
        print(f"    {col}: {coverage:.1f}% è¦†ç›–çŽ‡")

    # ä¿å­˜
    print(f"ðŸ’¾ ä¿å­˜åˆå¹¶æ•°æ®åˆ°: {output_h5}")
    df_merged.to_hdf(output_h5, key='data', mode='w')

    print(f"âœ… åˆå¹¶å®Œæˆï¼")
    print(f"  æ–‡ä»¶å¤§å°: {Path(output_h5).stat().st_size / 1024 / 1024:.2f} MB")

    return df_merged


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='è½¬æ¢Tushareè´¢åŠ¡æ•°æ®ä¸ºHDF5æ ¼å¼')
    parser.add_argument(
        '--input',
        type=str,
        default='~/.qlib/qlib_data/cn_data/financial_data/a_share_financial_latest.csv',
        help='è¾“å…¥CSVæ–‡ä»¶è·¯å¾„'
    )
    parser.add_argument(
        '--output',
        type=str,
        default='~/.qlib/qlib_data/cn_data/financial_data/daily_pv_financial.h5',
        help='è¾“å‡ºHDF5æ–‡ä»¶è·¯å¾„'
    )
    parser.add_argument(
        '--merge-price',
        type=str,
        default=None,
        help='ä»·æ ¼æ•°æ®HDF5æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æžœéœ€è¦åˆå¹¶ï¼‰'
    )
    parser.add_argument(
        '--min-date',
        type=str,
        default='2010-01-01',
        help='æœ€å°æ—¥æœŸï¼ˆè¿‡æ»¤æ—©äºŽæ­¤æ—¥æœŸçš„æ•°æ®ï¼‰'
    )
    parser.add_argument(
        '--max-date',
        type=str,
        default=None,
        help='æœ€å¤§æ—¥æœŸï¼ˆè¿‡æ»¤æ™šäºŽæ­¤æ—¥æœŸçš„æ•°æ®ï¼‰'
    )

    args = parser.parse_args()

    # æ‰©å±•è·¯å¾„
    input_csv = Path(args.input).expanduser()
    output_h5 = Path(args.output).expanduser()

    if not input_csv.exists():
        print(f"âŒ é”™è¯¯: è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_csv}")
        return

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_h5.parent.mkdir(parents=True, exist_ok=True)

    # è½¬æ¢è´¢åŠ¡æ•°æ®
    df_financial = convert_financial_csv_to_hdf5(
        input_csv=str(input_csv),
        output_h5=str(output_h5),
        min_date=args.min_date,
        max_date=args.max_date,
    )

    # å¦‚æžœæŒ‡å®šäº†ä»·æ ¼æ•°æ®ï¼Œè¿›è¡Œåˆå¹¶
    if args.merge_price:
        price_h5 = Path(args.merge_price).expanduser()
        if price_h5.exists():
            merged_output = output_h5.parent / "daily_pv_financial_merged.h5"
            merge_financial_with_price(
                financial_h5=str(output_h5),
                price_h5=str(price_h5),
                output_h5=str(merged_output),
            )
        else:
            print(f"âš ï¸  è­¦å‘Š: ä»·æ ¼æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {price_h5}")

    print("\nâœ… å…¨éƒ¨å®Œæˆï¼")


if __name__ == "__main__":
    main()
