#!/usr/bin/env python3
"""
Qlib MPS è¡¥ä¸å®Œæ•´æ€§æµ‹è¯•

æ­¤è„šæœ¬æµ‹è¯• MPS è¡¥ä¸æ˜¯å¦ç ´åäº† Qlib çš„åŸæœ‰åŠŸèƒ½ã€‚

æµ‹è¯•å†…å®¹ï¼š
1. CPU è®­ç»ƒï¼ˆåŸæœ‰åŠŸèƒ½ï¼‰
2. MPS è®­ç»ƒï¼ˆæ–°åŠŸèƒ½ï¼‰
3. æ¨¡å‹ä¿å­˜å’ŒåŠ è½½
4. é¢„æµ‹åŠŸèƒ½
5. è®¾å¤‡åˆ‡æ¢å…¼å®¹æ€§

Usage:
    python3 test_qlib_mps_patch.py
"""

import sys
import os
import tempfile
import shutil
from pathlib import Path

# æ·»åŠ æµ‹è¯•ä¾èµ–
try:
    import numpy as np
    import pandas as pd
    import torch
    import torch.nn as nn
    from torch.utils.data import DataLoader, TensorDataset
except ImportError as e:
    print(f"âŒ ç¼ºå°‘ä¾èµ–: {e}")
    print("è¯·å®‰è£…: pip install numpy pandas torch")
    sys.exit(1)

print("=" * 70)
print("ğŸ§ª Qlib MPS è¡¥ä¸å®Œæ•´æ€§æµ‹è¯•")
print("=" * 70)
print()

# æµ‹è¯•ç»“æœ
test_results = []


def test_cpu_training():
    """æµ‹è¯• 1: CPU è®­ç»ƒåŠŸèƒ½ï¼ˆåŸæœ‰åŠŸèƒ½å¿…é¡»ä¿æŒï¼‰"""
    print("\nğŸ“‹ æµ‹è¯• 1: CPU è®­ç»ƒåŠŸèƒ½")

    try:
        # åˆ›å»ºç®€å•æ¨¡å‹
        model = nn.Linear(10, 1)
        device = torch.device("cpu")
        model.to(device)

        # åˆ›å»ºè™šæ‹Ÿæ•°æ®
        X = torch.randn(100, 10)
        y = torch.randn(100, 1)

        # è®­ç»ƒå¾ªç¯
        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
        criterion = nn.MSELoss()

        model.train()
        for epoch in range(5):
            optimizer.zero_grad()
            outputs = model(X)
            loss = criterion(outputs, y)
            loss.backward()
            optimizer.step()

        print(f"  âœ… CPU è®­ç»ƒæˆåŠŸï¼Œæœ€ç»ˆ Loss: {loss.item():.6f}")
        test_results.append(("CPU è®­ç»ƒ", True, None))
        return True

    except Exception as e:
        print(f"  âŒ CPU è®­ç»ƒå¤±è´¥: {e}")
        test_results.append(("CPU è®­ç»ƒ", False, str(e)))
        return False


def test_mps_training():
    """æµ‹è¯• 2: MPS è®­ç»ƒåŠŸèƒ½ï¼ˆæ–°åŠŸèƒ½ï¼‰"""
    print("\nğŸ“‹ æµ‹è¯• 2: MPS è®­ç»ƒåŠŸèƒ½")

    if not torch.backends.mps.is_available():
        print("  âš ï¸  MPS ä¸å¯ç”¨ï¼Œè·³è¿‡æ­¤æµ‹è¯•")
        test_results.append(("MPS è®­ç»ƒ", None, "MPS ä¸å¯ç”¨"))
        return False

    try:
        # åˆ›å»ºç®€å•æ¨¡å‹
        model = nn.Linear(10, 1)
        device = torch.device("mps")
        model.to(device)

        # åˆ›å»ºè™šæ‹Ÿæ•°æ®
        X = torch.randn(100, 10).to(device)
        y = torch.randn(100, 1).to(device)

        # è®­ç»ƒå¾ªç¯
        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
        criterion = nn.MSELoss()

        model.train()
        for epoch in range(5):
            optimizer.zero_grad()
            outputs = model(X)
            loss = criterion(outputs, y)
            loss.backward()
            optimizer.step()

        print(f"  âœ… MPS è®­ç»ƒæˆåŠŸï¼Œæœ€ç»ˆ Loss: {loss.item():.6f}")
        test_results.append(("MPS è®­ç»ƒ", True, None))
        return True

    except Exception as e:
        print(f"  âŒ MPS è®­ç»ƒå¤±è´¥: {e}")
        test_results.append(("MPS è®­ç»ƒ", False, str(e)))
        return False


def test_model_save_load():
    """æµ‹è¯• 3: æ¨¡å‹ä¿å­˜å’ŒåŠ è½½ï¼ˆå…³é”®åŠŸèƒ½ï¼‰"""
    print("\nğŸ“‹ æµ‹è¯• 3: æ¨¡å‹ä¿å­˜å’ŒåŠ è½½")

    try:
        with tempfile.TemporaryDirectory() as tmpdir:
            # åˆ›å»ºå¹¶è®­ç»ƒæ¨¡å‹
            model = nn.Linear(10, 1)
            device = torch.device("cpu")
            model.to(device)

            # è®­ç»ƒä¸€æ­¥
            X = torch.randn(10, 10)
            y = torch.randn(10, 1)
            optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
            criterion = nn.MSELoss()

            optimizer.zero_grad()
            outputs = model(X)
            loss = criterion(outputs, y)
            loss.backward()
            optimizer.step()

            # ä¿å­˜æ¨¡å‹
            save_path = Path(tmpdir) / "model.pt"
            torch.save(model.state_dict(), save_path)

            # åˆ›å»ºæ–°æ¨¡å‹å¹¶åŠ è½½
            model2 = nn.Linear(10, 1)
            model2.load_state_dict(torch.load(save_path))
            model2.to(device)

            # éªŒè¯å‚æ•°ä¸€è‡´
            for p1, p2 in zip(model.parameters(), model2.parameters()):
                if not torch.allclose(p1, p2):
                    raise ValueError("å‚æ•°ä¸åŒ¹é…")

        print(f"  âœ… æ¨¡å‹ä¿å­˜å’ŒåŠ è½½æˆåŠŸ")
        test_results.append(("æ¨¡å‹ä¿å­˜/åŠ è½½", True, None))
        return True

    except Exception as e:
        print(f"  âŒ æ¨¡å‹ä¿å­˜å’ŒåŠ è½½å¤±è´¥: {e}")
        test_results.append(("æ¨¡å‹ä¿å­˜/åŠ è½½", False, str(e)))
        return False


def test_prediction():
    """æµ‹è¯• 4: é¢„æµ‹åŠŸèƒ½"""
    print("\nğŸ“‹ æµ‹è¯• 4: é¢„æµ‹åŠŸèƒ½")

    try:
        # åˆ›å»ºå¹¶è®­ç»ƒæ¨¡å‹
        model = nn.Linear(10, 1)
        device = torch.device("cpu")
        model.to(device)
        model.eval()

        # æµ‹è¯•é¢„æµ‹
        X = torch.randn(5, 10)

        with torch.no_grad():
            predictions = model(X)

        if predictions.shape != (5, 1):
            raise ValueError(f"é¢„æµ‹å½¢çŠ¶é”™è¯¯: {predictions.shape}")

        print(f"  âœ… é¢„æµ‹æˆåŠŸï¼Œè¾“å‡ºå½¢çŠ¶: {predictions.shape}")
        test_results.append(("é¢„æµ‹åŠŸèƒ½", True, None))
        return True

    except Exception as e:
        print(f"  âŒ é¢„æµ‹å¤±è´¥: {e}")
        test_results.append(("é¢„æµ‹åŠŸèƒ½", False, str(e)))
        return False


def test_device_selection():
    """æµ‹è¯• 5: è®¾å¤‡é€‰æ‹©é€»è¾‘ï¼ˆè¡¥ä¸çš„æ ¸å¿ƒï¼‰"""
    print("\nğŸ“‹ æµ‹è¯• 5: è®¾å¤‡é€‰æ‹©é€»è¾‘")

    try:
        # æµ‹è¯•ä¸åŒçš„ GPU é…ç½®
        test_cases = [
            (None, "cpu", "GPU=None åº”ä½¿ç”¨ CPU"),
            (-1, "cpu", "GPU=-1 åº”ä½¿ç”¨ CPU"),
            (0, "mps", "GPU=0 åº”ä½¿ç”¨ MPSï¼ˆå¦‚æœå¯ç”¨ï¼‰"),
        ]

        for gpu_value, expected_device, description in test_cases:
            if gpu_value == 0 and not torch.backends.mps.is_available():
                print(f"  âš ï¸  è·³è¿‡: {description} (MPS ä¸å¯ç”¨)")
                continue

            if gpu_value is not None and gpu_value >= 0:
                if torch.cuda.is_available():
                    device = torch.device(f"cuda:{gpu_value}")
                elif torch.backends.mps.is_available():
                    device = torch.device("mps")
                else:
                    device = torch.device("cpu")
            else:
                device = torch.device("cpu")

            if device.type == expected_device:
                print(f"  âœ… {description}")
            else:
                print(f"  âŒ {description} - æœŸæœ› {expected_device}, å¾—åˆ° {device.type}")
                test_results.append(("è®¾å¤‡é€‰æ‹©", False, f"é…ç½® {gpu_value} å¤±è´¥"))
                return False

        test_results.append(("è®¾å¤‡é€‰æ‹©", True, None))
        return True

    except Exception as e:
        print(f"  âŒ è®¾å¤‡é€‰æ‹©æµ‹è¯•å¤±è´¥: {e}")
        test_results.append(("è®¾å¤‡é€‰æ‹©", False, str(e)))
        return False


def test_cache_clearing():
    """æµ‹è¯• 6: GPU ç¼“å­˜æ¸…ç†ï¼ˆè¡¥ä¸ä¿®æ”¹çš„éƒ¨åˆ†ï¼‰"""
    print("\nğŸ“‹ æµ‹è¯• 6: GPU ç¼“å­˜æ¸…ç†")

    try:
        # æµ‹è¯• CPU è®¾å¤‡ï¼ˆä¸ä¼šè§¦å‘æ¸…ç†ï¼‰
        device = torch.device("cpu")
        if device.type == "cuda":
            torch.cuda.empty_cache()
        elif device.type == "mps":
            import gc
            gc.collect()

        print(f"  âœ… ç¼“å­˜æ¸…ç†é€»è¾‘æ­£å¸¸ï¼ˆCPU è®¾å¤‡ï¼‰")
        test_results.append(("ç¼“å­˜æ¸…ç†", True, None))
        return True

    except Exception as e:
        print(f"  âŒ ç¼“å­˜æ¸…ç†å¤±è´¥: {e}")
        test_results.append(("ç¼“å­˜æ¸…ç†", False, str(e)))
        return False


def test_qlib_integration():
    """æµ‹è¯• 7: Qlib é›†æˆæµ‹è¯•ï¼ˆå¦‚æœå¯ç”¨ï¼‰"""
    print("\nğŸ“‹ æµ‹è¯• 7: Qlib é›†æˆæµ‹è¯•")

    try:
        import qlib
        from qlib.contrib.model.pytorch_general_nn import GeneralPTNN

        # æ£€æŸ¥è¡¥ä¸æ˜¯å¦åº”ç”¨
        import inspect
        source_file = inspect.getsourcefile(GeneralPTNN)

        with open(source_file, 'r') as f:
            content = f.read()

        # æ£€æŸ¥å…³é”®ä»£ç 
        checks = [
            ("MPS æ£€æµ‹", "torch.backends.mps.is_available()"),
            ("MPS è®¾å¤‡", 'torch.device("mps")'),
            ("è®¾å¤‡ç±»å‹æ£€æŸ¥", 'self.device.type == "mps"'),
        ]

        for check_name, check_str in checks:
            if check_str in content:
                print(f"  âœ… {check_name} - å·²åº”ç”¨è¡¥ä¸")
            else:
                print(f"  âŒ {check_name} - è¡¥ä¸æœªåº”ç”¨")
                test_results.append(("Qlib é›†æˆ", False, f"{check_name} ç¼ºå¤±"))
                return False

        test_results.append(("Qlib é›†æˆ", True, None))
        return True

    except ImportError:
        print("  âš ï¸  Qlib ä¸å¯ç”¨ï¼Œè·³è¿‡é›†æˆæµ‹è¯•")
        test_results.append(("Qlib é›†æˆ", None, "Qlib æœªå®‰è£…"))
        return False
    except Exception as e:
        print(f"  âŒ Qlib é›†æˆæµ‹è¯•å¤±è´¥: {e}")
        test_results.append(("Qlib é›†æˆ", False, str(e)))
        return False


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""

    print("ğŸš€ å¼€å§‹è¿è¡Œæµ‹è¯•...\n")

    # è¿è¡Œæµ‹è¯•
    test_cpu_training()
    test_mps_training()
    test_model_save_load()
    test_prediction()
    test_device_selection()
    test_cache_clearing()
    test_qlib_integration()

    # æ±‡æ€»ç»“æœ
    print("\n" + "=" * 70)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 70)

    passed = 0
    failed = 0
    skipped = 0

    for test_name, success, error in test_results:
        if success is True:
            print(f"âœ… {test_name}: é€šè¿‡")
            passed += 1
        elif success is False:
            print(f"âŒ {test_name}: å¤±è´¥")
            if error:
                print(f"   é”™è¯¯: {error}")
            failed += 1
        else:
            print(f"âš ï¸  {test_name}: è·³è¿‡ ({error})")
            skipped += 1

    print()
    print(f"æ€»è®¡: {len(test_results)} ä¸ªæµ‹è¯•")
    print(f"âœ… é€šè¿‡: {passed}")
    print(f"âŒ å¤±è´¥: {failed}")
    print(f"âš ï¸  è·³è¿‡: {skipped}")

    # åˆ¤æ–­æ€»ä½“ç»“æœ
    if failed == 0:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼è¡¥ä¸æ²¡æœ‰ç ´ååŸæœ‰åŠŸèƒ½ã€‚")
        return 0
    else:
        print(f"\nâš ï¸  {failed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥è¡¥ä¸æˆ–å›é€€ã€‚")
        return 1


if __name__ == "__main__":
    exit_code = run_all_tests()
    print("\n" + "=" * 70)
    sys.exit(exit_code)
