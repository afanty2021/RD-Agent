#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Embedding API æµ‹è¯•è„šæœ¬

ç”¨äºè¯Šæ–­RD-Agentä¸­embedding APIé…ç½®å’Œè°ƒç”¨æ˜¯å¦æ­£å¸¸ã€‚
"""

import os
import sys
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

def test_imports():
    """æµ‹è¯•å¿…è¦çš„åº“æ˜¯å¦å·²å®‰è£…"""
    print("=" * 60)
    print("1. æµ‹è¯•åº“å¯¼å…¥")
    print("=" * 60)

    try:
        import litellm
        # litellm å¯èƒ½æ²¡æœ‰ __version__ å±æ€§
        try:
            version = litellm.__version__
        except AttributeError:
            version = "æœªçŸ¥ç‰ˆæœ¬"
        print("âœ“ litellm å·²å®‰è£…, ç‰ˆæœ¬:", version)
    except ImportError as e:
        print("âœ— litellm æœªå®‰è£…:", e)
        return False

    try:
        import numpy as np
        print("âœ“ numpy å·²å®‰è£…")
    except ImportError as e:
        print("âœ— numpy æœªå®‰è£…:", e)
        return False

    print()
    return True


def test_env_config():
    """æµ‹è¯•ç¯å¢ƒå˜é‡é…ç½®"""
    print("=" * 60)
    print("2. æµ‹è¯•ç¯å¢ƒå˜é‡é…ç½®")
    print("=" * 60)

    # æ£€æŸ¥å…³é”®é…ç½®
    configs = {
        "OPENAI_API_KEY": "OpenAI API Key",
        "OPENAI_API_BASE": "OpenAI API Base",
        "EMBEDDING_OPENAI_API_KEY": "Embedding API Key",
        "EMBEDDING_OPENAI_BASE_URL": "Embedding Base URL",
        "LITELLM_EMBEDDING_MODEL": "LiteLLM Embedding Model",
        "DEEPSEEK_API_KEY": "DeepSeek API Key",
    }

    for env_var, desc in configs.items():
        value = os.getenv(env_var)
        if value:
            # éšè—APIå¯†é’¥çš„æ•æ„Ÿéƒ¨åˆ†
            if "KEY" in env_var or "SECRET" in env_var:
                display_value = value[:8] + "..." + value[-4:] if len(value) > 12 else "***"
            else:
                display_value = value
            print(f"âœ“ {desc} ({env_var}): {display_value}")
        else:
            print(f"âœ— {desc} ({env_var}): æœªè®¾ç½®")

    print()
    return True


def test_rdagent_settings():
    """æµ‹è¯•RD-Agentçš„LLMé…ç½®"""
    print("=" * 60)
    print("3. æµ‹è¯•RD-Agent LLMé…ç½®")
    print("=" * 60)

    try:
        from rdagent.oai.llm_conf import LLM_SETTINGS, LITELLM_SETTINGS

        print(f"âœ“ Backend: {LLM_SETTINGS.backend}")
        print(f"âœ“ Chat Model: {LLM_SETTINGS.chat_model}")
        print(f"âœ“ Embedding Model: {LLM_SETTINGS.embedding_model}")
        print(f"âœ“ Use Embedding Cache: {LLM_SETTINGS.use_embedding_cache}")
        print(f"âœ“ Dump Embedding Cache: {LLM_SETTINGS.dump_embedding_cache}")

        # æ£€æŸ¥ LiteLLM ç‰¹å®šé…ç½®
        print(f"âœ“ LiteLLM Env Prefix: {LITELLM_SETTINGS.model_fields['env_prefix'].default}")

    except Exception as e:
        print(f"âœ— åŠ è½½RD-Agenté…ç½®å¤±è´¥: {e}")
        return False

    print()
    return True


def test_litellm_embedding():
    """ç›´æ¥æµ‹è¯•LiteLLMçš„embeddingåŠŸèƒ½"""
    print("=" * 60)
    print("4. æµ‹è¯•LiteLLM Embedding APIè°ƒç”¨")
    print("=" * 60)

    try:
        from litellm import embedding
        from rdagent.oai.llm_conf import LLM_SETTINGS

        model_name = LLM_SETTINGS.embedding_model
        test_texts = ["è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬", "This is a test text"]

        print(f"ä½¿ç”¨æ¨¡å‹: {model_name}")
        print(f"æµ‹è¯•æ–‡æœ¬: {test_texts}")

        print("æ­£åœ¨è°ƒç”¨embedding API...")
        response = embedding(
            model=model_name,
            input=test_texts,
        )

        print(f"âœ“ Embedding APIè°ƒç”¨æˆåŠŸ!")
        print(f"  - è¿”å›æ•°é‡: {len(response.data)}")
        print(f"  - å‘é‡ç»´åº¦: {len(response.data[0]['embedding'])}")
        print(f"  - æ¨¡å‹: {response.model}")
        print(f"  - ç”¨é€”: {response.usage}")

        return True, response.data[0]['embedding']

    except Exception as e:
        print(f"âœ— Embedding APIè°ƒç”¨å¤±è´¥: {e}")
        print(f"  é”™è¯¯ç±»å‹: {type(e).__name__}")
        import traceback
        print("\nè¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        traceback.print_exc()
        return False, None


def test_rdagent_backend():
    """æµ‹è¯•RD-Agentçš„APIBackend embeddingåŠŸèƒ½"""
    print("=" * 60)
    print("5. æµ‹è¯•RD-Agent APIBackend Embedding")
    print("=" * 60)

    try:
        from rdagent.oai.llm_utils import APIBackend

        backend = APIBackend()
        test_text = "æµ‹è¯•RD-Agent embeddingåŠŸèƒ½"

        print(f"æµ‹è¯•æ–‡æœ¬: {test_text}")
        print("æ­£åœ¨è°ƒç”¨APIBackend.create_embedding()...")

        embedding_vector = backend.create_embedding(input_content=test_text)

        print(f"âœ“ APIBackend embeddingè°ƒç”¨æˆåŠŸ!")
        print(f"  - å‘é‡ç±»å‹: {type(embedding_vector)}")
        print(f"  - å‘é‡ç»´åº¦: {len(embedding_vector) if isinstance(embedding_vector, list) else 'N/A'}")
        print(f"  - å‰5ä¸ªå€¼: {embedding_vector[:5] if isinstance(embedding_vector, list) else 'N/A'}")

        return True, embedding_vector

    except Exception as e:
        print(f"âœ— APIBackend embeddingè°ƒç”¨å¤±è´¥: {e}")
        print(f"  é”™è¯¯ç±»å‹: {type(e).__name__}")
        import traceback
        print("\nè¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        traceback.print_exc()
        return False, None


def test_vector_base():
    """æµ‹è¯•VectorBaseçš„embeddingåŠŸèƒ½"""
    print("=" * 60)
    print("6. æµ‹è¯•VectorBase KnowledgeMetaData")
    print("=" * 60)

    try:
        from rdagent.components.knowledge_management.vector_base import KnowledgeMetaData

        doc = KnowledgeMetaData(
            content="è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æ¡£ï¼Œç”¨äºéªŒè¯VectorBaseçš„embeddingåŠŸèƒ½",
            label="test"
        )

        print(f"æ–‡æ¡£å†…å®¹: {doc.content}")
        print(f"æ–‡æ¡£æ ‡ç­¾: {doc.label}")
        print("æ­£åœ¨åˆ›å»ºembedding...")

        doc.create_embedding()

        if doc.embedding is not None:
            print(f"âœ“ KnowledgeMetaData embeddingåˆ›å»ºæˆåŠŸ!")
            print(f"  - å‘é‡ç±»å‹: {type(doc.embedding)}")
            print(f"  - å‘é‡ç»´åº¦: {len(doc.embedding) if hasattr(doc.embedding, '__len__') else 'N/A'}")
        else:
            print(f"âœ— embeddingä¸ºNoneï¼Œå¯èƒ½ä½¿ç”¨äº†fallbackæœºåˆ¶")

        return True

    except Exception as e:
        print(f"âœ— KnowledgeMetaData embeddingåˆ›å»ºå¤±è´¥: {e}")
        print(f"  é”™è¯¯ç±»å‹: {type(e).__name__}")
        import traceback
        print("\nè¯¦ç»†é”™è¯¯ä¿¡æ¯:")
        traceback.print_exc()
        return False


def main():
    """ä¸»æµ‹è¯•æµç¨‹"""
    print("\n" + "=" * 60)
    print("RD-Agent Embedding API è¯Šæ–­æµ‹è¯•")
    print("=" * 60 + "\n")

    results = []

    # 1. æµ‹è¯•åº“å¯¼å…¥
    if not test_imports():
        print("\nâŒ ç¼ºå°‘å¿…è¦çš„åº“ï¼Œè¯·å…ˆå®‰è£…ä¾èµ–")
        sys.exit(1)

    # 2. æµ‹è¯•ç¯å¢ƒå˜é‡
    test_env_config()

    # 3. æµ‹è¯•RD-Agenté…ç½®
    if not test_rdagent_settings():
        print("\nâš ï¸ RD-Agenté…ç½®åŠ è½½å¤±è´¥ï¼Œç»§ç»­æµ‹è¯•...")

    # 4. æµ‹è¯•LiteLLMç›´æ¥è°ƒç”¨
    litellm_success, embedding_vector = test_litellm_embedding()
    results.append(("LiteLLMç›´æ¥è°ƒç”¨", litellm_success))

    # 5. æµ‹è¯•RD-Agent APIBackend
    backend_success, _ = test_rdagent_backend()
    results.append(("APIBackend", backend_success))

    # 6. æµ‹è¯•VectorBase
    vector_success = test_vector_base()
    results.append(("VectorBase", vector_success))

    # è¾“å‡ºæ€»ç»“
    print("\n" + "=" * 60)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 60)

    for test_name, success in results:
        status = "âœ“ é€šè¿‡" if success else "âœ— å¤±è´¥"
        print(f"{test_name}: {status}")

    print()

    # ç»™å‡ºè¯Šæ–­å»ºè®®
    if all(r[1] for r in results):
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Embedding APIé…ç½®æ­£å¸¸ã€‚")
    else:
        print("âŒ å­˜åœ¨é—®é¢˜ï¼Œè¯·å‚è€ƒä»¥ä¸‹å»ºè®®ï¼š")
        print()

        for test_name, success in results:
            if not success:
                if test_name == "LiteLLMç›´æ¥è°ƒç”¨":
                    print(f"â€¢ {test_name}å¤±è´¥:")
                    print("  - æ£€æŸ¥ APIå¯†é’¥æ˜¯å¦æ­£ç¡®")
                    print("  - æ£€æŸ¥ API Base URLæ˜¯å¦æ­£ç¡®")
                    print("  - æ£€æŸ¥æ¨¡å‹åç§°æ˜¯å¦æ”¯æŒ")
                    print("  - æ£€æŸ¥ç½‘ç»œè¿æ¥")
                    print()
                elif test_name == "APIBackend":
                    print(f"â€¢ {test_name}å¤±è´¥:")
                    print("  - æ£€æŸ¥ LiteLLM é…ç½®")
                    print("  - æ£€æŸ¥ç¼“å­˜è®¾ç½®")
                    print()
                elif test_name == "VectorBase":
                    print(f"â€¢ {test_name}å¤±è´¥:")
                    print("  - æ£€æŸ¥ fallback æœºåˆ¶æ˜¯å¦ç”Ÿæ•ˆ")
                    print("  - æŸ¥çœ‹è­¦å‘Šä¿¡æ¯")
                    print()

    print("\nå»ºè®®çš„é…ç½®ç¤ºä¾‹:")
    print("-" * 60)
    print("# åœ¨ .env æ–‡ä»¶ä¸­é…ç½®:")
    print("OPENAI_API_KEY=your-api-key")
    print("OPENAI_API_BASE=https://api.openai.com/v1")
    print("EMBEDDING_MODEL=text-embedding-3-small")
    print()
    print("# æˆ–è€…ä½¿ç”¨ DeepSeek + æ™ºè°±AI:")
    print("OPENAI_API_KEY=your-deepseek-key")
    print("OPENAI_API_BASE=https://api.deepseek.com/v1")
    print("CHAT_MODEL=deepseek-chat")
    print("EMBEDDING_OPENAI_API_KEY=your-zhipu-key")
    print("EMBEDDING_OPENAI_BASE_URL=https://open.bigmodel.cn/api/paas/v4")
    print("LITELLM_EMBEDDING_MODEL=zhipuai/embedding-2")
    print("-" * 60)


if __name__ == "__main__":
    main()
